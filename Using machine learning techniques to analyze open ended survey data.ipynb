{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Machine Learning techniques to build predictive models using open ended survey data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Using-Machine-Learning-techniques-to-build-predictive-models-using-open-ended-survey-data\" data-toc-modified-id=\"Using-Machine-Learning-techniques-to-build-predictive-models-using-open-ended-survey-data-0\">Using Machine Learning techniques to build predictive models using open ended survey data</a></span></li><li><span><a href=\"#0.-importing-libraries-and-setting-up-data\" data-toc-modified-id=\"0.-importing-libraries-and-setting-up-data-1\">0. importing libraries and setting up data</a></span></li><li><span><a href=\"#1.-Make-class-to-perform-the-different-kinds-of-CV\" data-toc-modified-id=\"1.-Make-class-to-perform-the-different-kinds-of-CV-2\">1. Make class to perform the different kinds of CV</a></span></li><li><span><a href=\"#2.--Modelling-using-pre-coded-features\" data-toc-modified-id=\"2.--Modelling-using-pre-coded-features-3\">2.  Modelling using pre-coded features</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Naive-bayes\" data-toc-modified-id=\"2.1-Naive-bayes-3.1\">2.1 Naive bayes</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.2--Multinomial-Naive-Bayes\" data-toc-modified-id=\"2.1.2--Multinomial-Naive-Bayes-3.1.1\">2.1.2  Multinomial Naive Bayes</a></span></li><li><span><a href=\"#2.1.3-Complement-Naive-Bayes\" data-toc-modified-id=\"2.1.3-Complement-Naive-Bayes-3.1.2\">2.1.3 Complement Naive Bayes</a></span></li></ul></li><li><span><a href=\"#1.2-Random-Forest\" data-toc-modified-id=\"1.2-Random-Forest-3.2\">1.2 Random Forest</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.2.1-Default-RF\" data-toc-modified-id=\"1.2.1-Default-RF-3.2.1\">1.2.1 Default RF</a></span></li><li><span><a href=\"#1.2.2-Tuned-RF\" data-toc-modified-id=\"1.2.2-Tuned-RF-3.2.2\">1.2.2 Tuned RF</a></span></li></ul></li><li><span><a href=\"#1.3-XGBoost-classifier\" data-toc-modified-id=\"1.3-XGBoost-classifier-3.3\">1.3 XGBoost classifier</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.3.1-Default-XGBoost\" data-toc-modified-id=\"1.3.1-Default-XGBoost-3.3.1\">1.3.1 Default XGBoost</a></span></li><li><span><a href=\"#1.3.2-Tuned-XGBoost\" data-toc-modified-id=\"1.3.2-Tuned-XGBoost-3.3.2\">1.3.2 Tuned XGBoost</a></span></li></ul></li></ul></li><li><span><a href=\"#2.-Modelling-using-topic-models\" data-toc-modified-id=\"2.-Modelling-using-topic-models-4\">2. Modelling using topic models</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-create-dataset\" data-toc-modified-id=\"2.1-create-dataset-4.1\">2.1 create dataset</a></span></li><li><span><a href=\"#2.2-Clean-data\" data-toc-modified-id=\"2.2-Clean-data-4.2\">2.2 Clean data</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.2.1-Remove-punctuation,-numbers-and-non-alphabetic-characters\" data-toc-modified-id=\"2.2.1-Remove-punctuation,-numbers-and-non-alphabetic-characters-4.2.1\">2.2.1 Remove punctuation, numbers and non alphabetic characters</a></span></li><li><span><a href=\"#2.2.2-Remove-stopwords\" data-toc-modified-id=\"2.2.2-Remove-stopwords-4.2.2\">2.2.2 Remove stopwords</a></span></li><li><span><a href=\"#2.2.3-Lemmatizing\" data-toc-modified-id=\"2.2.3-Lemmatizing-4.2.3\">2.2.3 Lemmatizing</a></span></li></ul></li><li><span><a href=\"#2.3-Inspect-and-visualize-most-occuring-words\" data-toc-modified-id=\"2.3-Inspect-and-visualize-most-occuring-words-4.3\">2.3 Inspect and visualize most occuring words</a></span></li><li><span><a href=\"#2.4-Latent-Semantic-Analysis-(LSA)\" data-toc-modified-id=\"2.4-Latent-Semantic-Analysis-(LSA)-4.4\">2.4 Latent Semantic Analysis (LSA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.4.1-Find-number-of-topics-with-best-coherence-score\" data-toc-modified-id=\"2.4.1-Find-number-of-topics-with-best-coherence-score-4.4.1\">2.4.1 Find number of topics with best coherence score</a></span></li><li><span><a href=\"#2.4.2-Naive-bayes-with-BOW\" data-toc-modified-id=\"2.4.2-Naive-bayes-with-BOW-4.4.2\">2.4.2 Naive bayes with BOW</a></span></li><li><span><a href=\"#2.4.3-Random-Forest-with-BOW\" data-toc-modified-id=\"2.4.3-Random-Forest-with-BOW-4.4.3\">2.4.3 Random Forest with BOW</a></span></li><li><span><a href=\"#2.4.4-XGBoost-with-BOW\" data-toc-modified-id=\"2.4.4-XGBoost-with-BOW-4.4.4\">2.4.4 XGBoost with BOW</a></span></li><li><span><a href=\"#2.4.5-Naive-bayes-with-tfidf\" data-toc-modified-id=\"2.4.5-Naive-bayes-with-tfidf-4.4.5\">2.4.5 Naive bayes with tfidf</a></span></li><li><span><a href=\"#2.4.6-RF-with-TF-IDF\" data-toc-modified-id=\"2.4.6-RF-with-TF-IDF-4.4.6\">2.4.6 RF with TF-IDF</a></span></li><li><span><a href=\"#2.4.7-XGBOOST-with-TF-IDF\" data-toc-modified-id=\"2.4.7-XGBOOST-with-TF-IDF-4.4.7\">2.4.7 XGBOOST with TF-IDF</a></span></li></ul></li><li><span><a href=\"#2.5-Latent-Dirichlet-Allocation-(LDA)\" data-toc-modified-id=\"2.5-Latent-Dirichlet-Allocation-(LDA)-4.5\">2.5 Latent Dirichlet Allocation (LDA)</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.5.1-Naive-bayes-with-BOW\" data-toc-modified-id=\"2.5.1-Naive-bayes-with-BOW-4.5.1\">2.5.1 Naive bayes with BOW</a></span></li><li><span><a href=\"#2.5.2-Random-forest-with-BOW\" data-toc-modified-id=\"2.5.2-Random-forest-with-BOW-4.5.2\">2.5.2 Random forest with BOW</a></span></li><li><span><a href=\"#2.5.3-XGBOOST-with-BOW\" data-toc-modified-id=\"2.5.3-XGBOOST-with-BOW-4.5.3\">2.5.3 XGBOOST with BOW</a></span></li><li><span><a href=\"#2.5.4-naive-bayes-with-TFIDF\" data-toc-modified-id=\"2.5.4-naive-bayes-with-TFIDF-4.5.4\">2.5.4 naive bayes with TFIDF</a></span></li><li><span><a href=\"#2.5.5-Random-Forest-with-TF-IDF\" data-toc-modified-id=\"2.5.5-Random-Forest-with-TF-IDF-4.5.5\">2.5.5 Random Forest with TF-IDF</a></span></li><li><span><a href=\"#2.5.6-XGBOOST-with-TF-IDF\" data-toc-modified-id=\"2.5.6-XGBOOST-with-TF-IDF-4.5.6\">2.5.6 XGBOOST with TF-IDF</a></span></li></ul></li></ul></li><li><span><a href=\"#3.-Interpretation-of-topics\" data-toc-modified-id=\"3.-Interpretation-of-topics-5\">3. Interpretation of topics</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-best-overall-model:-Random-Forest-(LSA-&amp;-TF-IDF)\" data-toc-modified-id=\"3.1-best-overall-model:-Random-Forest-(LSA-&amp;-TF-IDF)-5.1\">3.1 best overall model: Random Forest (LSA &amp; TF-IDF)</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1.1-Performance-using-3-topics\" data-toc-modified-id=\"3.1.1-Performance-using-3-topics-5.1.1\">3.1.1 Performance using 3 topics</a></span></li><li><span><a href=\"#3.1.2-Performance-using-5-topics\" data-toc-modified-id=\"3.1.2-Performance-using-5-topics-5.1.2\">3.1.2 Performance using 5 topics</a></span></li></ul></li><li><span><a href=\"#3.2-Topics-with-best-LDA-model:-Random-Forest-with-TF-IDF\" data-toc-modified-id=\"3.2-Topics-with-best-LDA-model:-Random-Forest-with-TF-IDF-5.2\">3.2 Topics with best LDA model: Random Forest with TF-IDF</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. importing libraries and setting up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning/manipulation, plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# modelling with sklearn \n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.naive_bayes import MultinomialNB \n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from pprint import pprint\n",
    "# xgboost and tuning\n",
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "# packages for dealing with text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import spacy\n",
    "from gensim.models import CoherenceModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import TfidfModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import string\n",
    "# topic models\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1479, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excl_mark</th>\n",
       "      <th>flooding</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>capital_letters</th>\n",
       "      <th>total_positive</th>\n",
       "      <th>density_positive</th>\n",
       "      <th>Thank_Appreciation</th>\n",
       "      <th>Sollicit_future_visit</th>\n",
       "      <th>Positive_closing_wish</th>\n",
       "      <th>Express_positive_feeling</th>\n",
       "      <th>Compliment_as_motivator</th>\n",
       "      <th>Refer_compliment</th>\n",
       "      <th>Promote_facility_service_values</th>\n",
       "      <th>Express_hope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,023255814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,008130081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   excl_mark  flooding  emoticons  capital_letters  total_positive  \\\n",
       "0          0         0          0                0               0   \n",
       "1          1         0          0                0               1   \n",
       "2          1         0          0                0               1   \n",
       "3          0         0          0                0               0   \n",
       "4          0         0          0                0               0   \n",
       "\n",
       "  density_positive  Thank_Appreciation  Sollicit_future_visit  \\\n",
       "0                0                 1.0                    1.0   \n",
       "1      0,023255814                 1.0                    1.0   \n",
       "2      0,008130081                 1.0                    1.0   \n",
       "3                0                 1.0                    1.0   \n",
       "4                0                 1.0                    1.0   \n",
       "\n",
       "   Positive_closing_wish  Express_positive_feeling  Compliment_as_motivator  \\\n",
       "0                    0.0                       2.0                      0.0   \n",
       "1                    0.0                       1.0                      0.0   \n",
       "2                    0.0                       1.0                      0.0   \n",
       "3                    0.0                       2.0                      0.0   \n",
       "4                    0.0                       2.0                      0.0   \n",
       "\n",
       "   Refer_compliment  Promote_facility_service_values  Express_hope  \n",
       "0               0.0                              0.0           0.0  \n",
       "1               0.0                              0.0           0.0  \n",
       "2               0.0                              0.0           0.0  \n",
       "3               0.0                              0.0           0.0  \n",
       "4               0.0                              0.0           0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data and rename columns\n",
    "df = pd.read_csv('APF_NF_N.csv', sep=';')\n",
    "df = df.rename(columns = {'excl_positive_TOTAL': 'excl_mark', 'flood_positive_TOTAL':'flooding', \n",
    "                         'emoticon_positive_TOTAL':'emoticons', 'caps_positive_TOTAL':'capital_letters', \n",
    "                         'APF_positive_TOTAL':'total_positive', 'APF_positive_DENSITY':'density_positive' })\n",
    "\n",
    "# select the relevant columns for model\n",
    "X_columns = ['excl_mark', 'flooding', 'emoticons', 'capital_letters',\n",
    "       'total_positive', 'density_positive']\n",
    "y_columns = ['Thank_Appreciation', 'Sollicit_future_visit',\n",
    "       'Positive_closing_wish', 'Express_positive_feeling',\n",
    "       'Compliment_as_motivator', 'Refer_compliment',\n",
    "       'Promote_facility_service_values', 'Express_hope']\n",
    "reviews = df.loc[:,X_columns + y_columns]\n",
    "\n",
    "# replace cells containing NA with 0 (NA here means that it is not present in review)\n",
    "reviews.fillna(0, inplace=True)\n",
    "print(reviews.shape)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make density of type float\n",
    "reviews.density_positive = reviews.density_positive.apply(lambda x: re.sub(',', '.', x)).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in predictors and response dataset and transform to binary responses\n",
    "X = reviews.iloc[:,:5]\n",
    "Y = reviews.iloc[:,6:]\n",
    "Y[Y > 1] = 1\n",
    "Y = Y.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Make class to perform the different kinds of CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to evaluate the model (and perform nested CV)\n",
    "class Model_eval:\n",
    "    def __init__(self, X, Y, classifier, modelname, metrics):\n",
    "        self.X, self.Y, self.clf, self.name = X, Y, classifier, modelname\n",
    "        scores = {}\n",
    "        for metric in metrics:\n",
    "            scores[metric] = []\n",
    "        self.scores = scores\n",
    "        self.metrics = metrics\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "            F1 = f1_score(y_true, y_pred, average='micro') * 100\n",
    "            recall = recall_score(y_true, y_pred, average='micro') * 100\n",
    "            precision = precision_score(y_true, y_pred, average='micro', zero_division=0) * 100\n",
    "            hamming = hamming_loss(y_true, y_pred) * 100\n",
    "            accuracy = accuracy_score(y_true, y_pred) * 100 \n",
    "            return F1, recall, precision, hamming, accuracy\n",
    "    \n",
    "    def perform_CV(self, splits=5):\n",
    "        print(50 * '-', '\\n')\n",
    "        print('Algorithm:', self.name)\n",
    "        print('    Folds:')\n",
    "\n",
    "        # define the outer loop\n",
    "        cv = MultilabelStratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "        # loop over the different folds (using the index provided by the outer cv function)\n",
    "        fold = 1\n",
    "        for train_idx, valid_idx in list(cv.split(self.X, self.Y)):\n",
    "            # fit the model on the training fold \n",
    "            self.clf.fit(self.X.iloc[train_idx,:], self.Y.iloc[train_idx,:]) \n",
    "            print()\n",
    "            print('     Fold:', fold)\n",
    "\n",
    "            # test performance of the model on the test fold\n",
    "            y_pred, y_true= self.clf.predict(self.X.iloc[valid_idx,:]), self.Y.iloc[valid_idx,:]\n",
    "            # add the performance metric to the scores\n",
    "            for metric, score in zip(self.metrics, self.calculate_metrics(y_true, y_pred)):\n",
    "                self.scores[metric].append(score)\n",
    "                if metric in self.metrics[:3]:\n",
    "                    print(f\"        {metric}: {self.scores[metric][-1]:.2f}%\")\n",
    "            fold += 1\n",
    "    \n",
    "\n",
    "        # print the average test score (of the different metrics) of the algorithm (with std dev.)\n",
    "        print('\\n    Average over all folds:')\n",
    "        for metric, score in self.scores.items():\n",
    "            print(f'        {metric} {np.mean(score):.2f}% +/- {np.std(score):.2f}')\n",
    "            # make the container with scores empty \n",
    "            self.scores[metric] = []\n",
    "        \n",
    "       \n",
    "    def perform_nested_CV(self, parameters, inner_splits = 3, outer_splits = 5, \n",
    "                          random=False, iterations=100, cm=False):\n",
    "            # make inner loop \n",
    "            inner_cv = MultilabelStratifiedKFold(n_splits=inner_splits, shuffle=True, random_state=0)\n",
    "\n",
    "            # make gridsearch objects (that will perform the CV search on the training fold of the outer loop)\n",
    "            if random:\n",
    "                gcv = RandomizedSearchCV(estimator = self.clf, \n",
    "                                         param_distributions = parameters,\n",
    "                                         scoring='f1_micro',\n",
    "                                         n_iter = iterations, \n",
    "                                         cv = inner_cv, \n",
    "                                         verbose=1, \n",
    "                                         n_jobs = -1)\n",
    "            \n",
    "            \n",
    "            else:\n",
    "                gcv = GridSearchCV(estimator=self.clf,\n",
    "                                   param_grid=parameters,\n",
    "                                   scoring='f1_micro',\n",
    "                                   n_jobs=-1,\n",
    "                                   cv=inner_cv,\n",
    "                                   verbose=1)\n",
    "            \n",
    "            # make the outer folds\n",
    "            print(50 * '-', '\\n')\n",
    "            print('Algorithm:', self.name)\n",
    "            print('    Inner loop:')\n",
    "            \n",
    "            # define the outer loop\n",
    "            outer_cv = MultilabelStratifiedKFold(n_splits=outer_splits, shuffle=True, random_state=0)\n",
    "\n",
    "            # loop over the different outer folds \n",
    "            for train_idx, test_idx in list(outer_cv.split(self.X, self.Y)):\n",
    "                # fit the gridsearch object on the training fold\n",
    "                # it will split it again in folds and perform a gridsearchCV determening the best parameters\n",
    "                gcv.fit(self.X.iloc[train_idx,:], self.Y.iloc[train_idx,:]) \n",
    "                print(f'\\n        Best Micro F1 score (inner test folds): {gcv.best_score_ * 100:.2f}%')\n",
    "                print('        Best parameters:', gcv.best_params_)\n",
    "\n",
    "                # test performance of best tuned model on the outer loop test fold\n",
    "                # and store the performance\n",
    "                y_pred, y_true = gcv.best_estimator_.predict(self.X.iloc[test_idx,:]), self.Y.iloc[test_idx,:]\n",
    "                for metric, score in zip(self.metrics, self.calculate_metrics(y_true, y_pred)):\n",
    "                    self.scores[metric].append(score)\n",
    "                    if metric in metrics[:3]:\n",
    "                        print(f\"        {metric} (on outer loop): {self.scores[metric][-1]:.2f}%\")\n",
    "                if cm:\n",
    "                    pprint(multilabel_confusion_matrix(y_true, y_pred))\n",
    "            \n",
    "            # print the average performance of the procedure on the test folds\n",
    "            # and print its stability\n",
    "            print('\\n    Average over all folds:')\n",
    "            for metric, score in self.scores.items():\n",
    "                print(f'        {metric} {np.mean(score):.2f}% +/- {np.std(score):.2f}')\n",
    "                self.scores[metric] = []\n",
    "    \n",
    "    def perform_bayesian_opt_pre(self, space, max_evals=20, lda=False,lsa=False,\n",
    "                                 inner_splits=2,outer_splits=3, cm=False):\n",
    "        # define a function that will perform bayesian optimization and returns the best hyperparameters found \n",
    "        def perform_bayes_opt(X_train, Y_train, X_val, Y_val, space, max_evals, lda, lsa):\n",
    "    # perform bayesian optimization (hyperopt) to find the best hyperparameters using the train and validation fold\n",
    "    # define objective function. Metric to be optimized is the F1 score \n",
    "            def objective(space):\n",
    "                clf=ClassifierChain(\n",
    "                    xgb.XGBClassifier(\n",
    "                        n_estimators=int(space['n_estimators']), max_depth=int(space['max_depth']), gamma=space['gamma'],\n",
    "                        scale_pos_weight=space['scale_pos_weight'], colsample_bytree=space['colsample_bytree'],\n",
    "                        learning_rate=space['learning_rate'], min_child_weight=space['min_child_weight'], \n",
    "                        objective=\"binary:logistic\", eval_metric = 'aucpr', use_label_encoder=False))\n",
    "                # if no topic model, just fit the xgboost classifier\n",
    "                if lda == False and lsa == False:\n",
    "                    clf.fit(X_train, Y_train)\n",
    "                    pred = clf.predict(X_val)\n",
    "                    f1 = f1_score(Y_val, pred, average='micro')\n",
    "                    return {'loss':-f1, 'status':STATUS_OK}\n",
    "               # else fit a pipeline that extracts the topics and uses them as predictors \n",
    "                else:\n",
    "                    if lda:\n",
    "                        topic_model = LatentDirichletAllocation(n_components = int(space['n_components']), \n",
    "                                                                max_iter=100, random_state=0)\n",
    "                    else:\n",
    "                        topic_model = TruncatedSVD(n_components = int(space['n_components']), \n",
    "                                                   random_state=0, n_iter=100)\n",
    "                \n",
    "                pipe = Pipeline([('svd', topic_model),\n",
    "                                ('classifier', clf)])\n",
    "                \n",
    "                # fit on the inner training fold of the outer training fold\n",
    "                pipe.fit(X_train, Y_train)\n",
    "\n",
    "                # measure performance of the validation fold of the outer training fold\n",
    "                pred = pipe.predict(X_val)\n",
    "                f1 = f1_score(Y_val, pred, average='micro')\n",
    "                return {'loss': -f1, 'status': STATUS_OK }\n",
    "\n",
    "            trials = Trials()\n",
    "\n",
    "            best_hyperparams = fmin(fn = objective,\n",
    "                                    space = space,\n",
    "                                    algo = tpe.suggest,\n",
    "                                    max_evals = max_evals,\n",
    "                                    trials = trials)\n",
    "            best_hyperparams['max_depth'] = int(best_hyperparams['max_depth'])\n",
    "            best_hyperparams['n_estimators'] = int(best_hyperparams['n_estimators'])\n",
    "            if lda != False or lsa != False:\n",
    "                best_hyperparams['n_components'] = int(best_hyperparams['n_components'])\n",
    "            return best_hyperparams\n",
    "        # NESTED CROSS VALIDATION \n",
    "        # define two loops \n",
    "        inner_cv = MultilabelStratifiedKFold(n_splits=inner_splits, shuffle=True, random_state=0)\n",
    "        outer_cv = MultilabelStratifiedKFold(n_splits=outer_splits, shuffle=True, random_state=0)\n",
    "\n",
    "        # loop over the outer folds\n",
    "        for train_idx, test_idx in list(outer_cv.split(self.X, self.Y)):\n",
    "\n",
    "            # make the inner training set \n",
    "            X_train = self.X.iloc[train_idx, :]\n",
    "            Y_train = self.Y.iloc[train_idx, :]\n",
    "\n",
    "            # make list to capture best parameters\n",
    "            inner_scores = {}\n",
    "\n",
    "            # split the inner trainig set into a training and validation fold for tuning\n",
    "            for training_idx, valid_idx in list(inner_cv.split(X_train, Y_train)):\n",
    "                # perform bayesian optimization\n",
    "                best_hyperparams = perform_bayes_opt(X_train.iloc[training_idx, :],\n",
    "                                                      Y_train.iloc[training_idx,:],\n",
    "                                                      X_train.iloc[valid_idx,:],\n",
    "                                                      Y_train.iloc[valid_idx,:],\n",
    "                                                      space,\n",
    "                                                      max_evals,\n",
    "                                                      lda,\n",
    "                                                      lsa)\n",
    "                if lda or lsa:\n",
    "                    n_components = best_hyperparams.pop('n_components')\n",
    "                # get performance of these hyperparameters, to store the best ones\n",
    "                clf = ClassifierChain(xgb.XGBClassifier(random_state=0, objective = 'binary:logistic', \n",
    "                                                        eval_metric='aucpr', \n",
    "                                                          use_label_encoder=False, **best_hyperparams))\n",
    "                \n",
    "                if lda == False and lsa == False:\n",
    "                    clf.fit(X_train.iloc[training_idx,:], Y_train.iloc[training_idx,:])\n",
    "                    pred = clf.predict(X_train.iloc[valid_idx, :])\n",
    "                else:\n",
    "                    if lda:\n",
    "                        topic_model = LatentDirichletAllocation(n_components = int(n_components),\n",
    "                                                                max_iter=100, random_state=0)\n",
    "                    else:\n",
    "                        topic_model = TruncatedSVD(n_components = int(n_components), \n",
    "                                                   random_state=0, n_iter=100)\n",
    "                    pipe = Pipeline([('svd', topic_model),\n",
    "                                     ('classifier', clf)])\n",
    "                    pipe.fit(X_train.iloc[training_idx,:], Y_train.iloc[training_idx,:])\n",
    "                    pred = pipe.predict(X_train.iloc[valid_idx, :])\n",
    "                    best_hyperparams['n_components'] = n_components\n",
    "                f1 = f1_score(Y_train.iloc[valid_idx,:], pred, average='micro')\n",
    "                print('Score on inner loop', f1, '\\n', best_hyperparams)\n",
    "                print()\n",
    "                inner_scores[f1] = best_hyperparams \n",
    "\n",
    "            # determine the best parameters\n",
    "            parameters = inner_scores[max(inner_scores.keys())]\n",
    "            print('Best hyperparameters found in inner loop')\n",
    "            print(parameters)\n",
    "            print()\n",
    "            if lda != False or lsa != False:\n",
    "                n_components = parameters.pop('n_components')\n",
    "            # fit a model with the best hyperparameters found in the inner loop with CV \n",
    "            clf = ClassifierChain(\n",
    "                    xgb.XGBClassifier(random_state=0, objective = 'binary:logistic', eval_metric='aucpr', \n",
    "                                      use_label_encoder=False, \n",
    "                                  **parameters))\n",
    "            \n",
    "            if lda == False and lsa == False:\n",
    "                clf.fit(X_train, Y_train)\n",
    "                pred = clf.predict(self.X.iloc[test_idx,:])\n",
    "            else:\n",
    "                if lda:\n",
    "                    topic_model = LatentDirichletAllocation(n_components = int(n_components), max_iter=100, random_state=0)\n",
    "                else:\n",
    "                    topic_model = TruncatedSVD(n_components = int(n_components), random_state=0, n_iter=100)\n",
    "                pipe = Pipeline([('svd', topic_model),\n",
    "                                 ('classifier', clf)])\n",
    "                # fit the model on the entire training fold\n",
    "                pipe.fit(X_train, Y_train)\n",
    "                pred = pipe.predict(self.X.iloc[test_idx,:])\n",
    "\n",
    "            # test performance of the model on the test fold and store performance\n",
    "            print()\n",
    "            print('Performance on the outer test fold:')\n",
    "            y_pred, y_true = pred, self.Y.iloc[test_idx,:]\n",
    "            for metric, score in zip(self.metrics, self.calculate_metrics(y_true, y_pred)):\n",
    "                    self.scores[metric] = self.scores.get(metric, []) + [score]\n",
    "                    if metric in self.metrics[:3]:\n",
    "                        print(f\"        {metric} (on outer loop): {self.scores[metric][-1]:.2f}%\")\n",
    "            if cm:\n",
    "                pprint(multilabel_confusion_matrix(y_true, y_pred))\n",
    "            print()\n",
    "\n",
    "        # print the average performance of the procedure on the test folds\n",
    "        # and print its stability\n",
    "        print('\\n    Average over all folds:')\n",
    "        for metric, score in self.scores.items():\n",
    "            print(f'        {metric} {np.mean(score):.2f}% +/- {np.std(score):.2f}')\n",
    "            self.scores[metric] = []\n",
    "metrics = ['Micro F1', 'Micro Recall', 'Micro Precision', 'Hamming', 'Accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code for nested CV based on code from Sebastian Raschka\n",
    "https://github.com/rasbt/stat451-machine-learning-fs20/blob/master/L11/code/11-eval4-algo__nested-cv_verbose1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Modelling using pre-coded features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2  Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these algorithms there are not really important tuning parameters so no nested CV is necessary. Instead a normal CV is used on the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Multinomial Naive Bayes\n",
      "    Folds:\n",
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 0.00%\n",
      "        Micro Recall: 0.00%\n",
      "        Micro Precision: 0.00%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 0.60%\n",
      "        Micro Recall: 0.30%\n",
      "        Micro Precision: 100.00%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 0.60%\n",
      "        Micro Recall: 0.30%\n",
      "        Micro Precision: 20.00%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 2.37%\n",
      "        Micro Recall: 1.21%\n",
      "        Micro Precision: 57.14%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 1.79%\n",
      "        Micro Recall: 0.90%\n",
      "        Micro Precision: 100.00%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 1.07% +/- 0.87\n",
      "        Micro Recall 0.54% +/- 0.44\n",
      "        Micro Precision 55.43% +/- 40.75\n",
      "        Hamming 13.99% +/- 0.07\n",
      "        Accuracy 64.03% +/- 0.49\n"
     ]
    }
   ],
   "source": [
    "MNB = Model_eval(X, Y, \n",
    "                 ClassifierChain(MultinomialNB(), order = 'random', random_state=0), \n",
    "                 'Multinomial Naive Bayes', metrics)\n",
    "MNB.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Complement Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Multinomial Naive Bayes\n",
      "    Folds:\n",
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 29.26%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Micro Recall: 25.53%\n",
      "        Micro Precision: 34.27%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 10.13%\n",
      "        Micro Recall: 6.02%\n",
      "        Micro Precision: 31.75%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 6.15%\n",
      "        Micro Recall: 3.65%\n",
      "        Micro Precision: 19.67%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 6.81%\n",
      "        Micro Recall: 3.94%\n",
      "        Micro Precision: 25.00%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 13.10%\n",
      "        Micro Recall: 7.81%\n",
      "        Micro Precision: 40.62%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 13.09% +/- 8.46\n",
      "        Micro Recall 9.39% +/- 8.21\n",
      "        Micro Precision 30.26% +/- 7.29\n",
      "        Hamming 15.49% +/- 0.98\n",
      "        Accuracy 62.14% +/- 1.72\n"
     ]
    }
   ],
   "source": [
    "CNB = Model_eval(X, Y, \n",
    "                 ClassifierChain(ComplementNB(), order = 'random', random_state=0),\n",
    "                 'Multinomial Naive Bayes',\n",
    "                 metrics)\n",
    "CNB.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 Default RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = Model_eval(X, Y, \n",
    "                RandomForestClassifier(random_state=0), \n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 36.60%\n",
      "        Micro Recall: 25.23%\n",
      "        Micro Precision: 66.67%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 40.81%\n",
      "        Micro Recall: 30.42%\n",
      "        Micro Precision: 61.96%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 38.11%\n",
      "        Micro Recall: 29.48%\n",
      "        Micro Precision: 53.89%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 38.76%\n",
      "        Micro Recall: 28.48%\n",
      "        Micro Precision: 60.65%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 41.72%\n",
      "        Micro Recall: 32.13%\n",
      "        Micro Precision: 59.44%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 39.20% +/- 1.85\n",
      "        Micro Recall 29.15% +/- 2.30\n",
      "        Micro Precision 60.52% +/- 4.12\n",
      "        Hamming 12.64% +/- 0.38\n",
      "        Accuracy 63.56% +/- 0.97\n"
     ]
    }
   ],
   "source": [
    "RF.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2 Tuned RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model \n",
    "RF_tuned = Model_eval(X, Y, \n",
    "                RandomForestClassifier(random_state=0), \n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the parameter grid \n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "max_features = ['auto', 'log2']\n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'class_weight': weights}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform random gridsearch\n",
    "RF_tuned.perform_nested_CV(grid, inner_splits=2, iterations = 100, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific grid \n",
    "n_estimators = [300, 500, 1000, 1500]\n",
    "max_depth = [5, 15, 50] \n",
    "min_samples_split = [3, 20]\n",
    "min_samples_leaf = [2, 3]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}]]\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "       'class_weight': weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 48.37%\n",
      "        Best parameters: {'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 1000}\n",
      "        Micro F1 (on outer loop): 48.44%\n",
      "        Micro Recall (on outer loop): 88.59%\n",
      "        Micro Precision (on outer loop): 33.33%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 48.48%\n",
      "        Best parameters: {'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}], 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 300}\n",
      "        Micro F1 (on outer loop): 47.99%\n",
      "        Micro Recall (on outer loop): 87.95%\n",
      "        Micro Precision (on outer loop): 32.99%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 48.24%\n",
      "        Best parameters: {'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}], 'max_depth': 5, 'min_samples_leaf': 3, 'min_samples_split': 20, 'n_estimators': 300}\n",
      "        Micro F1 (on outer loop): 48.30%\n",
      "        Micro Recall (on outer loop): 88.75%\n",
      "        Micro Precision (on outer loop): 33.18%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 48.29%\n",
      "        Best parameters: {'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}], 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 1500}\n",
      "        Micro F1 (on outer loop): 48.23%\n",
      "        Micro Recall (on outer loop): 88.79%\n",
      "        Micro Precision (on outer loop): 33.11%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 48.28%\n",
      "        Best parameters: {'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 3, 'n_estimators': 300}\n",
      "        Micro F1 (on outer loop): 48.44%\n",
      "        Micro Recall (on outer loop): 88.59%\n",
      "        Micro Precision (on outer loop): 33.33%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 48.28% +/- 0.17\n",
      "        Micro Recall 88.53% +/- 0.30\n",
      "        Micro Precision 33.19% +/- 0.13\n",
      "        Hamming 26.56% +/- 0.09\n",
      "        Accuracy 19.88% +/- 0.55\n"
     ]
    }
   ],
   "source": [
    "RF_tuned.perform_nested_CV(grid, inner_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "XGB = Model_eval(X, Y, \n",
    "                      ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'aucpr', use_label_encoder=False, seed=0)),\n",
    "                      'xgboost',\n",
    "                      metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Default XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: xgboost\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 37.58%\n",
      "        Micro Recall: 26.13%\n",
      "        Micro Precision: 66.92%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 39.75%\n",
      "        Micro Recall: 29.22%\n",
      "        Micro Precision: 62.18%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 38.11%\n",
      "        Micro Recall: 29.48%\n",
      "        Micro Precision: 53.89%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 38.33%\n",
      "        Micro Recall: 27.88%\n",
      "        Micro Precision: 61.33%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 42.94%\n",
      "        Micro Recall: 33.33%\n",
      "        Micro Precision: 60.33%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 39.34% +/- 1.94\n",
      "        Micro Recall 29.21% +/- 2.38\n",
      "        Micro Precision 60.93% +/- 4.19\n",
      "        Hamming 12.59% +/- 0.39\n",
      "        Accuracy 63.89% +/- 0.98\n"
     ]
    }
   ],
   "source": [
    "XGB.perform_CV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Tuned XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class\n",
    "XGB = Model_eval(X, Y, \n",
    "                 ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", \n",
    "                                                   eval_metric = 'aucpr', use_label_encoder=False, seed=0)),\n",
    "                 'xgboost',\n",
    "                 metrics)\n",
    "# define parameter space to search\n",
    "space={ 'max_depth': hp.quniform(\"max_depth\", 2, 50, 1),\n",
    "        'gamma': hp.uniform ('gamma', 0,9),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'scale_pos_weight' : hp.uniform('scale_pos_weight', 0,5),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100,1000,50),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [04:45<00:00,  2.85s/trial, best loss: -0.48228346456692917]\n",
      "Score on inner loop 0.48228346456692917 \n",
      " {'colsample_bytree': 0.8636959072079329, 'gamma': 8.460133878646698, 'learning_rate': 0.08392143015662391, 'max_depth': 16, 'min_child_weight': 9.0, 'n_estimators': 450, 'scale_pos_weight': 3.679733621538283}\n",
      "\n",
      "100%|| 100/100 [04:51<00:00,  2.91s/trial, best loss: -0.4815361890694239]\n",
      "Score on inner loop 0.4815361890694239 \n",
      " {'colsample_bytree': 0.945506859391246, 'gamma': 4.573311675242717, 'learning_rate': 0.1268014363176787, 'max_depth': 31, 'min_child_weight': 0.0, 'n_estimators': 550, 'scale_pos_weight': 3.714244730958503}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.8636959072079329, 'gamma': 8.460133878646698, 'learning_rate': 0.08392143015662391, 'max_depth': 16, 'min_child_weight': 9.0, 'n_estimators': 450, 'scale_pos_weight': 3.679733621538283}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 48.30%\n",
      "        Micro Recall (on outer loop): 88.63%\n",
      "        Micro Precision (on outer loop): 33.20%\n",
      "\n",
      "100%|| 100/100 [04:50<00:00,  2.91s/trial, best loss: -0.48177339901477834]\n",
      "Score on inner loop 0.48177339901477834 \n",
      " {'colsample_bytree': 0.5154530545091307, 'gamma': 6.888718953743646, 'learning_rate': 0.004706638101762205, 'max_depth': 40, 'min_child_weight': 6.0, 'n_estimators': 600, 'scale_pos_weight': 2.8631243165472373}\n",
      "\n",
      "100%|| 100/100 [03:58<00:00,  2.39s/trial, best loss: -0.4827925270403146]\n",
      "Score on inner loop 0.4827925270403146 \n",
      " {'colsample_bytree': 0.7038689425522686, 'gamma': 4.954751891068028, 'learning_rate': 0.025738362235541486, 'max_depth': 35, 'min_child_weight': 0.0, 'n_estimators': 100, 'scale_pos_weight': 3.2581682316700507}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.7038689425522686, 'gamma': 4.954751891068028, 'learning_rate': 0.025738362235541486, 'max_depth': 35, 'min_child_weight': 0.0, 'n_estimators': 100, 'scale_pos_weight': 3.2581682316700507}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 48.18%\n",
      "        Micro Recall (on outer loop): 88.75%\n",
      "        Micro Precision (on outer loop): 33.06%\n",
      "\n",
      "100%|| 100/100 [02:27<00:00,  1.47s/trial, best loss: -0.48102513553474613]\n",
      "Score on inner loop 0.48102513553474613 \n",
      " {'colsample_bytree': 0.9288829294879981, 'gamma': 0.20302113698267202, 'learning_rate': 0.07603119259559607, 'max_depth': 49, 'min_child_weight': 8.0, 'n_estimators': 400, 'scale_pos_weight': 3.513517241769992}\n",
      "\n",
      "100%|| 100/100 [03:36<00:00,  2.16s/trial, best loss: -0.48520710059171596]\n",
      "Score on inner loop 0.48520710059171596 \n",
      " {'colsample_bytree': 0.7151490739803468, 'gamma': 0.5365832263035154, 'learning_rate': 0.011534063836626699, 'max_depth': 44, 'min_child_weight': 2.0, 'n_estimators': 600, 'scale_pos_weight': 4.424918082371791}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.7151490739803468, 'gamma': 0.5365832263035154, 'learning_rate': 0.011534063836626699, 'max_depth': 44, 'min_child_weight': 2.0, 'n_estimators': 600, 'scale_pos_weight': 4.424918082371791}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 47.67%\n",
      "        Micro Recall (on outer loop): 90.04%\n",
      "        Micro Precision (on outer loop): 32.42%\n",
      "\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 48.05% +/- 0.27\n",
      "        Micro Recall 89.14% +/- 0.64\n",
      "        Micro Precision 32.89% +/- 0.34\n",
      "        Hamming 26.99% +/- 0.47\n",
      "        Accuracy 19.27% +/- 0.92\n"
     ]
    }
   ],
   "source": [
    "# perform nested CV with bayes optimization\n",
    "XGB.perform_bayesian_opt_pre(space,max_evals=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Modelling using topic models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete rows with empty reviews\n",
    "index_NA = df[df.text_review.isnull().values].index\n",
    "df = df.drop(index=index_NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select text columns from dataset \n",
    "body = pd.DataFrame(df.loc[:,'text_review'])\n",
    "body.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(+) Goede kamer, goed bed, inloopdouche fijn v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(+) Zeer uitgebreid ontbijt en lekker!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"(+) De hygine en de inrichting van de kamers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(+) Goede bedden, makkelijk bereikbaar vanaf s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(+) Heerlijk bed. Veel TV kanalen, Goede voorz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>\"(+) Ontbijt was heerlijk, alles was aanwezig ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>\"(+) Bedden waren schoon\\n\\n(-) Oud! Garage ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>(-) enorme renovatie in het pand, dus naast he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>\"(+) Het ontbijt De service\\n\\n(-) De kamer wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>\"(+) Vriendelijk personeel, goed ontbijt.\\n\\n(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text_review\n",
       "0     (+) Goede kamer, goed bed, inloopdouche fijn v...\n",
       "1                (+) Zeer uitgebreid ontbijt en lekker!\n",
       "2     \"(+) De hygine en de inrichting van de kamers...\n",
       "3     (+) Goede bedden, makkelijk bereikbaar vanaf s...\n",
       "4     (+) Heerlijk bed. Veel TV kanalen, Goede voorz...\n",
       "...                                                 ...\n",
       "1474  \"(+) Ontbijt was heerlijk, alles was aanwezig ...\n",
       "1475  \"(+) Bedden waren schoon\\n\\n(-) Oud! Garage ou...\n",
       "1476  (-) enorme renovatie in het pand, dus naast he...\n",
       "1477  \"(+) Het ontbijt De service\\n\\n(-) De kamer wa...\n",
       "1478  \"(+) Vriendelijk personeel, goed ontbijt.\\n\\n(...\n",
       "\n",
       "[1440 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Thank_Appreciation</th>\n",
       "      <th>Sollicit_future_visit</th>\n",
       "      <th>Positive_closing_wish</th>\n",
       "      <th>Express_positive_feeling</th>\n",
       "      <th>Compliment_as_motivator</th>\n",
       "      <th>Refer_compliment</th>\n",
       "      <th>Promote_facility_service_values</th>\n",
       "      <th>Express_hope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Thank_Appreciation  Sollicit_future_visit  Positive_closing_wish  \\\n",
       "0                      1                      1                      0   \n",
       "1                      1                      1                      0   \n",
       "2                      1                      1                      0   \n",
       "3                      1                      1                      0   \n",
       "4                      1                      1                      0   \n",
       "...                  ...                    ...                    ...   \n",
       "1474                   0                      0                      0   \n",
       "1475                   0                      0                      0   \n",
       "1476                   0                      0                      0   \n",
       "1477                   0                      0                      0   \n",
       "1478                   0                      0                      0   \n",
       "\n",
       "      Express_positive_feeling  Compliment_as_motivator  Refer_compliment  \\\n",
       "0                            1                        0                 0   \n",
       "1                            1                        0                 0   \n",
       "2                            1                        0                 0   \n",
       "3                            1                        0                 0   \n",
       "4                            1                        0                 0   \n",
       "...                        ...                      ...               ...   \n",
       "1474                         0                        0                 0   \n",
       "1475                         0                        0                 0   \n",
       "1476                         0                        0                 0   \n",
       "1477                         0                        0                 0   \n",
       "1478                         0                        0                 0   \n",
       "\n",
       "      Promote_facility_service_values  Express_hope  \n",
       "0                                   0             0  \n",
       "1                                   0             0  \n",
       "2                                   0             0  \n",
       "3                                   0             0  \n",
       "4                                   0             0  \n",
       "...                               ...           ...  \n",
       "1474                                0             0  \n",
       "1475                                0             0  \n",
       "1476                                0             0  \n",
       "1477                                0             0  \n",
       "1478                                0             0  \n",
       "\n",
       "[1440 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create response dataset\n",
    "Y = df.iloc[:,18:26]\n",
    "Y[Y > 1] = 1\n",
    "Y = Y.fillna(0).astype(int)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Clean data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classic steps in cleaning text data\n",
    "1. Put everything to lowercase\n",
    "2. get rid of punctuation\n",
    "3. get rid of numbers\n",
    "4. get rid of stopwords\n",
    "5. standardize words using lemmatiziation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Remove punctuation, numbers and non alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all characters lowercase and remove punctuation and (+) & (-) & \\n\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    # remove non alphabetic characters\n",
    "    text = re.sub('[(+)|(-)|\\n|\"||]', '', text)\n",
    "    # remove digits\n",
    "    text = re.sub('\\d+', '', text)\n",
    "    # remove puncutation\n",
    "    text = re.sub('[%s]+' % re.escape(string.punctuation), '', text)\n",
    "    # remove redundant spaces\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "body['clean_text'] = body['text_review'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stop_words):\n",
    "    text = [word for word in text.split(' ') if word not in stop_words]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('dutch')\n",
    "body['clean_text'] = body['clean_text'].apply(lambda x: remove_stopwords(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_review</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(+) Goede kamer, goed bed, inloopdouche fijn v...</td>\n",
       "      <td>goede kamer goed bed inloopdouche fijn gehandi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(+) Zeer uitgebreid ontbijt en lekker!</td>\n",
       "      <td>zeer uitgebreid ontbijt lekker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"(+) De hygine en de inrichting van de kamers...</td>\n",
       "      <td>hygine inrichting kamers niks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(+) Goede bedden, makkelijk bereikbaar vanaf s...</td>\n",
       "      <td>goede bedden makkelijk bereikbaar vanaf snelwe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(+) Heerlijk bed. Veel TV kanalen, Goede voorz...</td>\n",
       "      <td>heerlijk bed tv kanalen goede voorzieningen ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_review  \\\n",
       "0  (+) Goede kamer, goed bed, inloopdouche fijn v...   \n",
       "1             (+) Zeer uitgebreid ontbijt en lekker!   \n",
       "2  \"(+) De hygine en de inrichting van de kamers...   \n",
       "3  (+) Goede bedden, makkelijk bereikbaar vanaf s...   \n",
       "4  (+) Heerlijk bed. Veel TV kanalen, Goede voorz...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  goede kamer goed bed inloopdouche fijn gehandi...  \n",
       "1                     zeer uitgebreid ontbijt lekker  \n",
       "2                     hygine inrichting kamers niks  \n",
       "3  goede bedden makkelijk bereikbaar vanaf snelwe...  \n",
       "4  heerlijk bed tv kanalen goede voorzieningen ha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Lemmatizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dutch library\n",
    "def perform_lemmatizing(text, core):\n",
    "    sentence = core(text)\n",
    "    transformed = [word.lemma_ for word in sentence]\n",
    "    return ' '.join(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"nl_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "body['clean_text_lemma'] = body['clean_text'].apply(lambda x: perform_lemmatizing(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_review</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_text_lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(+) Goede kamer, goed bed, inloopdouche fijn v...</td>\n",
       "      <td>goede kamer goed bed inloopdouche fijn gehandi...</td>\n",
       "      <td>goed kamer goed bed inloopdouch fijn gehandica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(+) Zeer uitgebreid ontbijt en lekker!</td>\n",
       "      <td>zeer uitgebreid ontbijt lekker</td>\n",
       "      <td>zeer uitbreiden ontbijt lekker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"(+) De hygine en de inrichting van de kamers...</td>\n",
       "      <td>hygine inrichting kamers niks</td>\n",
       "      <td>hygine inrichting kamer niks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(+) Goede bedden, makkelijk bereikbaar vanaf s...</td>\n",
       "      <td>goede bedden makkelijk bereikbaar vanaf snelwe...</td>\n",
       "      <td>goed bed makkelijk bereikbaar vanaf snelweg mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(+) Heerlijk bed. Veel TV kanalen, Goede voorz...</td>\n",
       "      <td>heerlijk bed tv kanalen goede voorzieningen ha...</td>\n",
       "      <td>heerlijk bed tv kanaal goed voorziening handig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text_review  \\\n",
       "0  (+) Goede kamer, goed bed, inloopdouche fijn v...   \n",
       "1             (+) Zeer uitgebreid ontbijt en lekker!   \n",
       "2  \"(+) De hygine en de inrichting van de kamers...   \n",
       "3  (+) Goede bedden, makkelijk bereikbaar vanaf s...   \n",
       "4  (+) Heerlijk bed. Veel TV kanalen, Goede voorz...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  goede kamer goed bed inloopdouche fijn gehandi...   \n",
       "1                     zeer uitgebreid ontbijt lekker   \n",
       "2                     hygine inrichting kamers niks   \n",
       "3  goede bedden makkelijk bereikbaar vanaf snelwe...   \n",
       "4  heerlijk bed tv kanalen goede voorzieningen ha...   \n",
       "\n",
       "                                    clean_text_lemma  \n",
       "0  goed kamer goed bed inloopdouch fijn gehandica...  \n",
       "1                     zeer uitbreiden ontbijt lekker  \n",
       "2                      hygine inrichting kamer niks  \n",
       "3  goed bed makkelijk bereikbaar vanaf snelweg mo...  \n",
       "4  heerlijk bed tv kanaal goed voorziening handig...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Inspect and visualize most occuring words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "data_CV = cv.fit_transform(body.clean_text_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aanbeveel</th>\n",
       "      <th>aanbevelen</th>\n",
       "      <th>aanbeveling</th>\n",
       "      <th>aanbieden</th>\n",
       "      <th>aanbieding</th>\n",
       "      <th>aanbod</th>\n",
       "      <th>aandacht</th>\n",
       "      <th>aandoen</th>\n",
       "      <th>aandringen</th>\n",
       "      <th>aanduiden</th>\n",
       "      <th>...</th>\n",
       "      <th>zwembad</th>\n",
       "      <th>zwembadruimte</th>\n",
       "      <th>zwemmen</th>\n",
       "      <th>zweterig</th>\n",
       "      <th>zwier</th>\n",
       "      <th>zwijgen</th>\n",
       "      <th>zr</th>\n",
       "      <th>n</th>\n",
       "      <th>nvoudig</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  4073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aanbeveel  aanbevelen  aanbeveling  aanbieden  aanbieding  aanbod  \\\n",
       "0             0           0            0          0           0       0   \n",
       "1             0           0            0          0           0       0   \n",
       "2             0           0            0          0           0       0   \n",
       "3             0           0            0          0           0       0   \n",
       "4             0           0            0          0           0       0   \n",
       "...         ...         ...          ...        ...         ...     ...   \n",
       "1435          0           0            0          0           0       0   \n",
       "1436          0           0            0          0           0       0   \n",
       "1437          0           0            0          0           0       0   \n",
       "1438          0           0            0          0           0       0   \n",
       "1439          0           0            0          0           0       0   \n",
       "\n",
       "      aandacht  aandoen  aandringen  aanduiden  ...  zwembad  zwembadruimte  \\\n",
       "0            0        0           0          0  ...        0              0   \n",
       "1            0        0           0          0  ...        0              0   \n",
       "2            0        0           0          0  ...        0              0   \n",
       "3            0        0           0          0  ...        0              0   \n",
       "4            0        0           0          0  ...        0              0   \n",
       "...        ...      ...         ...        ...  ...      ...            ...   \n",
       "1435         0        0           0          0  ...        0              0   \n",
       "1436         0        0           0          0  ...        0              0   \n",
       "1437         0        0           0          0  ...        0              0   \n",
       "1438         0        0           0          0  ...        0              0   \n",
       "1439         0        0           0          0  ...        0              0   \n",
       "\n",
       "      zwemmen  zweterig  zwier  zwijgen  zr  n  nvoudig  k  \n",
       "0           0         0      0        0     0    0          0    0  \n",
       "1           0         0      0        0     0    0          0    0  \n",
       "2           0         0      0        0     0    0          0    0  \n",
       "3           0         0      0        0     0    0          0    0  \n",
       "4           0         0      0        0     0    0          0    0  \n",
       "...       ...       ...    ...      ...   ...  ...        ...  ...  \n",
       "1435        0         0      0        0     0    0          0    0  \n",
       "1436        0         0      0        0     0    0          0    0  \n",
       "1437        0         0      0        0     0    0          0    0  \n",
       "1438        0         0      0        0     0    0          0    0  \n",
       "1439        0         0      0        0     0    0          0    0  \n",
       "\n",
       "[1440 rows x 4073 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_CV = pd.DataFrame(data_CV.toarray(), columns=cv.get_feature_names())\n",
    "dtm_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kamer          1085\n",
       "ontbijt         623\n",
       "goed            476\n",
       "hotel           414\n",
       "we              339\n",
       "bed             320\n",
       "personeel       319\n",
       "zeer            259\n",
       "vriendelijk     254\n",
       "heel            251\n",
       "locatie         242\n",
       "klein           202\n",
       "prima           201\n",
       "badkamer        199\n",
       "erg             189\n",
       "wel             184\n",
       "ligging         154\n",
       "mooi            148\n",
       "wij             147\n",
       "liggen          140\n",
       "schoon          138\n",
       "prijs           134\n",
       "hebben          131\n",
       "ruim            131\n",
       "lekker          114\n",
       "slecht          111\n",
       "gaan            110\n",
       "komen           110\n",
       "heerlijk        109\n",
       "leuk            105\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if some words that are mostly used are not useful add them to the stopwords to delete and \n",
    "# perfrom the count vectorizer again \n",
    "# find the most common words over all the documtents\n",
    "dtm = dtm_CV.transpose()\n",
    "dtm.sum(axis=1).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some words can also be categorized as stopwords: we, wel, wij -> remove these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kamer          1085\n",
       "ontbijt         623\n",
       "goed            476\n",
       "hotel           414\n",
       "bed             320\n",
       "personeel       319\n",
       "zeer            259\n",
       "vriendelijk     254\n",
       "heel            251\n",
       "locatie         242\n",
       "klein           202\n",
       "prima           201\n",
       "badkamer        199\n",
       "erg             189\n",
       "ligging         154\n",
       "mooi            148\n",
       "liggen          140\n",
       "schoon          138\n",
       "prijs           134\n",
       "ruim            131\n",
       "lekker          114\n",
       "slecht          111\n",
       "heerlijk        109\n",
       "leuk            105\n",
       "douche          103\n",
       "krijgen         102\n",
       "net             102\n",
       "staan            95\n",
       "nacht            92\n",
       "centrum          91\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new stopwords to remove\n",
    "stop_words = stop_words + (['we', 'wel','wij', 'komen','gaan','vinden'])\n",
    "\n",
    "# remove stopwords from the text\n",
    "body['clean_text_lemma'] = body['clean_text_lemma'].apply(lambda x: remove_stopwords(x, stop_words))\n",
    "\n",
    "# initialize the document term matrix again \n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(body.clean_text_lemma)\n",
    "data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "# transpose data and calculate for each token the number of occurences\n",
    "dtm = data_dtm.transpose()\n",
    "dtm.sum(axis=1).sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make 1 string with all the text in it\n",
    "text = ''.join(word for word in body.clean_text_lemma)\n",
    "\n",
    "# make plots \n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class to store document term matrices\n",
    "class data:\n",
    "    def __init__(self, bow_dtm, tfidf_dtm, Y):\n",
    "        self.bow = bow_dtm\n",
    "        self.tfidf = tfidf_dtm\n",
    "        self.Y = Y\n",
    "\n",
    "# bow document-term matrix\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(body.clean_text_lemma)\n",
    "dtm_CV = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "# tfidf document-term matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "data_tfidf = tfidf.fit_transform(body.clean_text_lemma)\n",
    "dtm_tfidf = pd.DataFrame(data_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "dtm = data(dtm_CV, dtm_tfidf, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Find number of topics with best coherence score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data in required format for gensim package\n",
    "data = []\n",
    "for text in body['clean_text_lemma']:\n",
    "    data.append(simple_preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.49027755919744037\n",
      "25 0.4761639668148874\n",
      "30 0.46590805781503614\n",
      "35 0.4495168454926935\n",
      "40 0.4423508296037741\n",
      "45 0.4170799397756698\n",
      "50 0.42620831438458107\n",
      "55 0.40924412945611044\n",
      "60 0.395630044100943\n",
      "65 0.3957825195330616\n",
      "70 0.38543791260054755\n",
      "75 0.38230976122672533\n",
      "80 0.37135819791961433\n",
      "85 0.3704785190783592\n",
      "90 0.366633698132494\n",
      "95 0.3626472072211304\n",
      "100 0.35314784687556383\n",
      "105 0.3523073740606559\n",
      "110 0.34095036902713477\n",
      "115 0.34117902489861385\n",
      "120 0.3432204120055123\n",
      "125 0.3383143760171268\n",
      "130 0.336050648841361\n",
      "135 0.3329837515433421\n",
      "140 0.3419220171587817\n",
      "145 0.34173687642107103\n",
      "150 0.33884394878145135\n",
      "155 0.34717186204363726\n",
      "160 0.3390148444030065\n",
      "165 0.3452070622709065\n",
      "170 0.34965623206318486\n",
      "175 0.345884394216666\n",
      "180 0.34633328980819056\n",
      "185 0.3573720358723022\n",
      "190 0.35852048922383023\n",
      "195 0.3616509869224252\n"
     ]
    }
   ],
   "source": [
    "# find number of topics with best coherence score (BOW)\n",
    "id2word = corpora.Dictionary(data)\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in data]\n",
    "values = {}\n",
    "for n in range(20,200,5):\n",
    "    lsa = LsiModel(doc_term_matrix, num_topics=n, id2word = id2word)\n",
    "    coherence_model_lsa = CoherenceModel(model=lsa, \n",
    "                                     texts=data, \n",
    "                                     dictionary=id2word, coherence='c_v')\n",
    "    values[n] = coherence_model_lsa.get_coherence()\n",
    "    print(n,coherence_model_lsa.get_coherence())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1b4cee5e5e0>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(values.keys(), values.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Naive bayes with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the pipeline that first performance LSA and then fits the Naive bayes on the output as predictors\n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf =  ClassifierChain(GaussianNB(), order = 'random', random_state=0)\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "GNB = Model_eval(dtm.bow, dtm.Y, \n",
    "                 pipe,\n",
    "                 'Gaussian Naive Bayes',\n",
    "                 metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune number of components/ topics\n",
    "grid = {'svd__n_components':[x for x in range(10,200,5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Gaussian Naive Bayes\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 37.55%\n",
      "        Best parameters: {'svd__n_components': 195}\n",
      "        Micro F1 (on outer loop): 34.39%\n",
      "        Micro Recall (on outer loop): 86.58%\n",
      "        Micro Precision (on outer loop): 21.46%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 37.63%\n",
      "        Best parameters: {'svd__n_components': 195}\n",
      "        Micro F1 (on outer loop): 36.00%\n",
      "        Micro Recall (on outer loop): 83.39%\n",
      "        Micro Precision (on outer loop): 22.96%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 36.84%\n",
      "        Best parameters: {'svd__n_components': 190}\n",
      "        Micro F1 (on outer loop): 34.43%\n",
      "        Micro Recall (on outer loop): 92.16%\n",
      "        Micro Precision (on outer loop): 21.17%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 39.82%\n",
      "        Best parameters: {'svd__n_components': 20}\n",
      "        Micro F1 (on outer loop): 38.52%\n",
      "        Micro Recall (on outer loop): 76.43%\n",
      "        Micro Precision (on outer loop): 25.75%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 37.30%\n",
      "        Best parameters: {'svd__n_components': 195}\n",
      "        Micro F1 (on outer loop): 37.24%\n",
      "        Micro Recall (on outer loop): 90.79%\n",
      "        Micro Precision (on outer loop): 23.42%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 36.12% +/- 1.61\n",
      "        Micro Recall 85.87% +/- 5.65\n",
      "        Micro Precision 22.95% +/- 1.64\n",
      "        Hamming 41.37% +/- 4.63\n",
      "        Accuracy 23.61% +/- 3.97\n"
     ]
    }
   ],
   "source": [
    "GNB.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Random Forest with BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "RF = Model_eval(dtm.bow, dtm.Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameter grid\n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "max_features = ['auto','log2','sqrt']\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__max_features': max_features,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'svd__n_components':[20,25,30,35,40,50,100,200,300, 400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 61.80%\n",
      "        Best parameters: {'svd__n_components': 35, 'classifier__n_estimators': 500, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 61.13%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 61.12%\n",
      "        Best parameters: {'svd__n_components': 200, 'classifier__n_estimators': 500, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 5, 'classifier__max_features': 'auto', 'classifier__max_depth': 50, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 62.57%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 60.23%\n",
      "        Best parameters: {'svd__n_components': 40, 'classifier__n_estimators': 500, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 'log2', 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 61.02%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 61.24%\n",
      "        Best parameters: {'svd__n_components': 50, 'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 'log2', 'classifier__max_depth': 15, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 61.69%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 60.37%\n",
      "        Best parameters: {'svd__n_components': 35, 'classifier__n_estimators': 100, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 63.54%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 61.99% +/- 0.95\n",
      "        Micro Recall 73.78% +/- 2.37\n",
      "        Micro Precision 53.51% +/- 1.66\n",
      "        Hamming 12.27% +/- 0.57\n",
      "        Accuracy 56.18% +/- 3.05\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 XGBoost with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline and initiliaze class\n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf = ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'aucpr', \n",
    "                                                        use_label_encoder=False, seed=0))\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "XGB = Model_eval(dtm.bow, dtm.Y,\n",
    "                pipe,\n",
    "                'XGBOOST', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify parameter space\n",
    "space={ 'max_depth': hp.quniform(\"max_depth\", 2, 50, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'scale_pos_weight' : hp.uniform('scale_pos_weight', 0,5),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100,1000,50),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_components': hp.quniform('n_components', 10,500, 20),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [09:20<00:00, 18.70s/trial, best loss: -0.5709251101321586]\n",
      "Score on inner loop 0.552584670231729 \n",
      " {'colsample_bytree': 0.8612126010686805, 'gamma': 5.034093496357436, 'learning_rate': 0.06043726736740364, 'max_depth': 6, 'min_child_weight': 10.0, 'n_estimators': 1000, 'scale_pos_weight': 3.601736080386474, 'n_components': 80}\n",
      "\n",
      "100%|| 30/30 [08:16<00:00, 16.55s/trial, best loss: -0.6080139372822301]\n",
      "Score on inner loop 0.5913043478260871 \n",
      " {'colsample_bytree': 0.8921650244842885, 'gamma': 1.2807706589334116, 'learning_rate': 0.06771683723090957, 'max_depth': 3, 'min_child_weight': 8.0, 'n_estimators': 750, 'scale_pos_weight': 3.5397688028618335, 'n_components': 80}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.8921650244842885, 'gamma': 1.2807706589334116, 'learning_rate': 0.06771683723090957, 'max_depth': 3, 'min_child_weight': 8.0, 'n_estimators': 750, 'scale_pos_weight': 3.5397688028618335, 'n_components': 80}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 61.83%\n",
      "        Micro Recall (on outer loop): 65.83%\n",
      "        Micro Precision (on outer loop): 58.29%\n",
      "\n",
      "100%|| 30/30 [11:50<00:00, 23.69s/trial, best loss: -0.5769944341372912]\n",
      "Score on inner loop 0.5769944341372912 \n",
      " {'colsample_bytree': 0.688087981795301, 'gamma': 8.063937634694962, 'learning_rate': 0.08960716469726099, 'max_depth': 23, 'min_child_weight': 6.0, 'n_estimators': 950, 'scale_pos_weight': 2.9647027698557333, 'n_components': 360}\n",
      "\n",
      "100%|| 30/30 [13:03<00:00, 26.13s/trial, best loss: -0.5647668393782384]\n",
      "Score on inner loop 0.5392070484581498 \n",
      " {'colsample_bytree': 0.9029031340327778, 'gamma': 5.5011338288508975, 'learning_rate': 0.06457338594620071, 'max_depth': 10, 'min_child_weight': 8.0, 'n_estimators': 350, 'scale_pos_weight': 3.6953191484083674, 'n_components': 340}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.688087981795301, 'gamma': 8.063937634694962, 'learning_rate': 0.08960716469726099, 'max_depth': 23, 'min_child_weight': 6.0, 'n_estimators': 950, 'scale_pos_weight': 2.9647027698557333, 'n_components': 360}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 62.82%\n",
      "        Micro Recall (on outer loop): 65.71%\n",
      "        Micro Precision (on outer loop): 60.18%\n",
      "\n",
      "100%|| 30/30 [12:34<00:00, 25.14s/trial, best loss: -0.5928338762214984]\n",
      "Score on inner loop 0.6032786885245902 \n",
      " {'colsample_bytree': 0.8838107174879445, 'gamma': 8.26909996956266, 'learning_rate': 0.08386378705906834, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 150, 'scale_pos_weight': 3.9797824882504127, 'n_components': 160}\n",
      "\n",
      "100%|| 30/30 [18:17<00:00, 36.57s/trial, best loss: -0.6045340050377834]\n",
      "Score on inner loop 0.5736170212765956 \n",
      " {'colsample_bytree': 0.7642346843116168, 'gamma': 7.407409770709361, 'learning_rate': 0.02784508096877492, 'max_depth': 15, 'min_child_weight': 4.0, 'n_estimators': 200, 'scale_pos_weight': 2.9902599166373984, 'n_components': 260}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.8838107174879445, 'gamma': 8.26909996956266, 'learning_rate': 0.08386378705906834, 'max_depth': 7, 'min_child_weight': 5.0, 'n_estimators': 150, 'scale_pos_weight': 3.9797824882504127, 'n_components': 160}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 61.70%\n",
      "        Micro Recall (on outer loop): 66.79%\n",
      "        Micro Precision (on outer loop): 57.33%\n",
      "\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 62.12% +/- 0.50\n",
      "        Micro Recall 66.11% +/- 0.49\n",
      "        Micro Precision 58.60% +/- 1.18\n",
      "        Hamming 10.93% +/- 0.28\n",
      "        Accuracy 64.31% +/- 1.23\n"
     ]
    }
   ],
   "source": [
    "XGB.perform_bayesian_opt_pre(space, max_evals=30, lsa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Naive bayes with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up \n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf =  ClassifierChain(GaussianNB(), order = 'random', random_state=0)\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "GNB = Model_eval(dtm.tfidf, dtm.Y, \n",
    "                 pipe,\n",
    "                 'Gaussian Naive Bayes',\n",
    "                 metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter space\n",
    "grid = {'svd__n_components':[x for x in range(10,200,5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Gaussian Naive Bayes\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 40.35%\n",
      "        Best parameters: {'svd__n_components': 80}\n",
      "        Micro F1 (on outer loop): 44.08%\n",
      "        Micro Recall (on outer loop): 42.81%\n",
      "        Micro Precision (on outer loop): 45.42%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 45.48%\n",
      "        Best parameters: {'svd__n_components': 110}\n",
      "        Micro F1 (on outer loop): 45.12%\n",
      "        Micro Recall (on outer loop): 47.28%\n",
      "        Micro Precision (on outer loop): 43.15%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 35.93%\n",
      "        Best parameters: {'svd__n_components': 120}\n",
      "        Micro F1 (on outer loop): 38.79%\n",
      "        Micro Recall (on outer loop): 62.75%\n",
      "        Micro Precision (on outer loop): 28.07%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 42.42%\n",
      "        Best parameters: {'svd__n_components': 100}\n",
      "        Micro F1 (on outer loop): 39.32%\n",
      "        Micro Recall (on outer loop): 40.76%\n",
      "        Micro Precision (on outer loop): 37.98%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 40.08%\n",
      "        Best parameters: {'svd__n_components': 120}\n",
      "        Micro F1 (on outer loop): 47.14%\n",
      "        Micro Recall (on outer loop): 64.13%\n",
      "        Micro Precision (on outer loop): 37.27%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 42.89% +/- 3.29\n",
      "        Micro Recall 51.55% +/- 9.94\n",
      "        Micro Precision 38.38% +/- 6.00\n",
      "        Hamming 18.70% +/- 4.15\n",
      "        Accuracy 55.28% +/- 6.38\n"
     ]
    }
   ],
   "source": [
    "GNB.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.6 RF with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "RF = Model_eval(dtm.tfidf, dtm.Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_estimators = [800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "max_features = ['auto','log2','sqrt']\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'classifier__max_features': max_features,\n",
    "        'svd__n_components':[20,25,30,35,40,50,100,200,300, 400]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 63.31%\n",
      "        Best parameters: {'svd__n_components': 50, 'classifier__n_estimators': 800, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 5, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 63.75%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 64.60%\n",
      "        Best parameters: {'svd__n_components': 30, 'classifier__n_estimators': 1500, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'auto', 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 62.23%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 64.81%\n",
      "        Best parameters: {'svd__n_components': 50, 'classifier__n_estimators': 800, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'log2', 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.2, 1: 0.8}, {0: 0.33, 1: 0.67}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}]}\n",
      "        Micro F1 (on outer loop): 63.13%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 63.22%\n",
      "        Best parameters: {'svd__n_components': 40, 'classifier__n_estimators': 1000, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 66.19%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 63.44%\n",
      "        Best parameters: {'svd__n_components': 40, 'classifier__n_estimators': 1500, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 5, 'classifier__max_features': 'log2', 'classifier__max_depth': 70, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 66.58%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 64.37% +/- 1.71\n",
      "        Micro Recall 73.39% +/- 2.67\n",
      "        Micro Precision 57.38% +/- 1.94\n",
      "        Hamming 11.01% +/- 0.61\n",
      "        Accuracy 59.72% +/- 1.34\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2, random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific grid\n",
    "n_estimators = [800]\n",
    "max_depth = [50, 100] \n",
    "min_samples_split = [3, 10]\n",
    "min_samples_leaf = [4, 5]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}]]\n",
    "max_features = ['sqrt','log2'] \n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'classifier__max_features': max_features,\n",
    "        'svd__n_components':[30,35,40]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fold 1 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 64.25%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 50, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 800, 'svd__n_components': 40}\n",
      "        Micro F1 (on outer loop): 62.96%\n",
      "        Micro Recall (on outer loop): 70.61%\n",
      "        Micro Precision (on outer loop): 56.81%\n",
      "Fold 2 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 63.31%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 50, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 5, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 800, 'svd__n_components': 30}\n",
      "        Micro F1 (on outer loop): 63.78%\n",
      "        Micro Recall (on outer loop): 77.64%\n",
      "        Micro Precision (on outer loop): 54.12%\n",
      "Fold 3 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 64.25%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 50, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 800, 'svd__n_components': 30}\n",
      "        Micro F1 (on outer loop): 64.36%\n",
      "        Micro Recall (on outer loop): 69.93%\n",
      "        Micro Precision (on outer loop): 59.61%\n",
      "Fold 4 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 62.11%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}], 'classifier__max_depth': 50, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 800, 'svd__n_components': 30}\n",
      "        Micro F1 (on outer loop): 64.36%\n",
      "        Micro Recall (on outer loop): 71.02%\n",
      "        Micro Precision (on outer loop): 58.84%\n",
      "Fold 5 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 63.15%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}], 'classifier__max_depth': 50, 'classifier__max_features': 'log2', 'classifier__min_samples_leaf': 4, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 800, 'svd__n_components': 40}\n",
      "        Micro F1 (on outer loop): 68.03%\n",
      "        Micro Recall (on outer loop): 79.05%\n",
      "        Micro Precision (on outer loop): 59.71%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 64.70% +/- 1.74\n",
      "        Micro Recall 73.65% +/- 3.87\n",
      "        Micro Precision 57.82% +/- 2.12\n",
      "        Hamming 10.89% +/- 0.67\n",
      "        Accuracy 60.76% +/- 1.51\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.7 XGBOOST with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "lsa = TruncatedSVD(random_state=0, n_iter=100)\n",
    "clf = ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'aucpr', \n",
    "                                                        use_label_encoder=False, seed=0))\n",
    "pipe = Pipeline([('svd', lsa),\n",
    "                ('classifier', clf)])\n",
    "XGB = Model_eval(dtm.tfidf, dtm.Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter space\n",
    "space={ 'max_depth': hp.quniform(\"max_depth\", 2, 50, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'scale_pos_weight' : hp.uniform('scale_pos_weight', 0,5),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100,1000,50),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_components': hp.quniform('n_components', 10,500, 20),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [07:47<00:00, 15.58s/trial, best loss: -0.5951134380453753]\n",
      "Score on inner loop 0.5951134380453753 \n",
      " {'colsample_bytree': 0.9053987618285813, 'gamma': 6.3343728296824064, 'learning_rate': 0.02907983551061663, 'max_depth': 23, 'min_child_weight': 8.0, 'n_estimators': 150, 'scale_pos_weight': 2.177849903534753, 'n_components': 220}\n",
      "\n",
      "100%|| 30/30 [06:55<00:00, 13.85s/trial, best loss: -0.615111111111111]\n",
      "Score on inner loop 0.615111111111111 \n",
      " {'colsample_bytree': 0.7105887012769158, 'gamma': 6.772875350693135, 'learning_rate': 0.12309449492551033, 'max_depth': 12, 'min_child_weight': 7.0, 'n_estimators': 300, 'scale_pos_weight': 2.2229417914040996, 'n_components': 140}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.7105887012769158, 'gamma': 6.772875350693135, 'learning_rate': 0.12309449492551033, 'max_depth': 12, 'min_child_weight': 7.0, 'n_estimators': 300, 'scale_pos_weight': 2.2229417914040996, 'n_components': 140}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 66.54%\n",
      "        Micro Recall (on outer loop): 66.99%\n",
      "        Micro Precision (on outer loop): 66.10%\n",
      "\n",
      "100%|| 30/30 [09:50<00:00, 19.70s/trial, best loss: -0.5669160432252702]\n",
      "Score on inner loop 0.5669160432252702 \n",
      " {'colsample_bytree': 0.645757691975984, 'gamma': 5.7008222973152725, 'learning_rate': 0.03899125604397143, 'max_depth': 28, 'min_child_weight': 8.0, 'n_estimators': 400, 'scale_pos_weight': 2.5794960214102836, 'n_components': 220}\n",
      "\n",
      "100%|| 30/30 [07:39<00:00, 15.32s/trial, best loss: -0.5756013745704468]\n",
      "Score on inner loop 0.5756013745704468 \n",
      " {'colsample_bytree': 0.6270632139766859, 'gamma': 8.19764425196349, 'learning_rate': 0.14681649535832383, 'max_depth': 17, 'min_child_weight': 10.0, 'n_estimators': 300, 'scale_pos_weight': 2.5607983885155976, 'n_components': 180}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.6270632139766859, 'gamma': 8.19764425196349, 'learning_rate': 0.14681649535832383, 'max_depth': 17, 'min_child_weight': 10.0, 'n_estimators': 300, 'scale_pos_weight': 2.5607983885155976, 'n_components': 180}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 62.39%\n",
      "        Micro Recall (on outer loop): 63.41%\n",
      "        Micro Precision (on outer loop): 61.41%\n",
      "\n",
      "100%|| 30/30 [07:29<00:00, 14.99s/trial, best loss: -0.6240458015267175]\n",
      "Score on inner loop 0.6240458015267175 \n",
      " {'colsample_bytree': 0.600903398568898, 'gamma': 2.533916044838631, 'learning_rate': 0.17453078130697075, 'max_depth': 16, 'min_child_weight': 9.0, 'n_estimators': 250, 'scale_pos_weight': 4.595058665499249, 'n_components': 60}\n",
      "\n",
      "100%|| 30/30 [06:18<00:00, 12.63s/trial, best loss: -0.6369668246445497]\n",
      "Score on inner loop 0.6369668246445497 \n",
      " {'colsample_bytree': 0.9920595377783666, 'gamma': 1.0869415404836995, 'learning_rate': 0.187701262239788, 'max_depth': 48, 'min_child_weight': 10.0, 'n_estimators': 150, 'scale_pos_weight': 2.7581581232541756, 'n_components': 200}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.9920595377783666, 'gamma': 1.0869415404836995, 'learning_rate': 0.187701262239788, 'max_depth': 48, 'min_child_weight': 10.0, 'n_estimators': 150, 'scale_pos_weight': 2.7581581232541756, 'n_components': 200}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 59.65%\n",
      "        Micro Recall (on outer loop): 54.89%\n",
      "        Micro Precision (on outer loop): 65.30%\n",
      "\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 62.86% +/- 2.83\n",
      "        Micro Recall 61.76% +/- 5.07\n",
      "        Micro Precision 64.27% +/- 2.05\n",
      "        Hamming 9.85% +/- 0.56\n",
      "        Accuracy 68.26% +/- 0.60\n"
     ]
    }
   ],
   "source": [
    "XGB.perform_bayesian_opt_pre(space,max_evals=30, lsa=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data in required format for gensim package\n",
    "data = []\n",
    "for text in body['clean_text_lemma']:\n",
    "    data.append(simple_preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 0.438650308867781\n",
      "25 0.4496447296303197\n",
      "30 0.4414422672675098\n",
      "35 0.44714394719582873\n",
      "40 0.4374228775262443\n",
      "45 0.4389973105496504\n",
      "50 0.4232393222230333\n",
      "55 0.4283890401610936\n",
      "60 0.4198187221399972\n",
      "65 0.4109262740409232\n",
      "70 0.4132593460390563\n",
      "75 0.4007088575245668\n",
      "80 0.42020335366657535\n",
      "85 0.4052701165764751\n",
      "90 0.40043730872173666\n",
      "95 0.4012332992077816\n",
      "100 0.3906585313866303\n",
      "105 0.40829648811627695\n",
      "110 0.39502516340212135\n",
      "115 0.4061068911703274\n",
      "120 0.38531453724452774\n",
      "125 0.3900807904226289\n",
      "130 0.38722444194437783\n",
      "135 0.3901025583007207\n",
      "140 0.3841743762535204\n",
      "145 0.39613678640578043\n",
      "150 0.3982726830075572\n",
      "155 0.42969309629461\n",
      "160 0.42552323129321046\n",
      "165 0.38853533974103033\n",
      "170 0.4163897285731032\n",
      "175 0.4166158828375537\n",
      "180 0.44627674456121663\n",
      "185 0.4141931750808759\n",
      "190 0.4357680936225781\n",
      "195 0.4613654489616092\n"
     ]
    }
   ],
   "source": [
    "# find number of topics with best coherence score \n",
    "id2word = corpora.Dictionary(data)\n",
    "doc_term_matrix = [id2word.doc2bow(doc) for doc in data]\n",
    "values = {}\n",
    "for n in range(20,200,5):\n",
    "    lda = LdaModel(doc_term_matrix, num_topics=n, id2word = id2word)\n",
    "    coherence_model_lda = CoherenceModel(model=lda, \n",
    "                                     texts=data, \n",
    "                                     dictionary=id2word, coherence='c_v')\n",
    "    values[n] = coherence_model_lda.get_coherence()\n",
    "    print(n,coherence_model_lda.get_coherence())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Naive bayes with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "lda = LatentDirichletAllocation(random_state=0, max_iter=100)\n",
    "clf =  ClassifierChain(GaussianNB(), order = 'random', random_state=0)\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                ('classifier', clf)])\n",
    "GNB = Model_eval(dtm.bow, dtm.Y, \n",
    "                 pipe,\n",
    "                 'Gaussian Naive Bayes',\n",
    "                 metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "grid = {'svd__n_components':[x for x in range(10,200,5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Gaussian Naive Bayes\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.50%\n",
      "        Best parameters: {'svd__n_components': 175}\n",
      "        Micro F1 (on outer loop): 47.72%\n",
      "        Micro Recall (on outer loop): 60.06%\n",
      "        Micro Precision (on outer loop): 39.58%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 54.53%\n",
      "        Best parameters: {'svd__n_components': 175}\n",
      "        Micro F1 (on outer loop): 51.63%\n",
      "        Micro Recall (on outer loop): 73.16%\n",
      "        Micro Precision (on outer loop): 39.90%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.09%\n",
      "        Best parameters: {'svd__n_components': 185}\n",
      "        Micro F1 (on outer loop): 46.43%\n",
      "        Micro Recall (on outer loop): 62.75%\n",
      "        Micro Precision (on outer loop): 36.85%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 53.88%\n",
      "        Best parameters: {'svd__n_components': 125}\n",
      "        Micro F1 (on outer loop): 47.46%\n",
      "        Micro Recall (on outer loop): 78.98%\n",
      "        Micro Precision (on outer loop): 33.93%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 51.81%\n",
      "        Best parameters: {'svd__n_components': 115}\n",
      "        Micro F1 (on outer loop): 47.35%\n",
      "        Micro Recall (on outer loop): 70.79%\n",
      "        Micro Precision (on outer loop): 35.57%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 48.12% +/- 1.81\n",
      "        Micro Recall 69.15% +/- 6.91\n",
      "        Micro Precision 37.16% +/- 2.30\n",
      "        Hamming 20.22% +/- 2.18\n",
      "        Accuracy 40.49% +/- 7.50\n"
     ]
    }
   ],
   "source": [
    "GNB.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Random forest with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set-up\n",
    "lda = LatentDirichletAllocation(random_state=0, max_iter=100)\n",
    "clf = RandomForestClassifier(n_jobs=-1, random_state=0)\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                ('classifier', clf)])\n",
    "RF = Model_eval(dtm.bow, dtm.Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "                 metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'svd__n_components':[20,25,30,35,40,50,100,200,300, 400],\n",
    "        'svd__doc_topic_prior':[0.05,0.1,0.5,1],\n",
    "        'svd__topic_word_prior': [0.05,0.1,0.5,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 22.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 25.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 56.52%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.05, 'svd__n_components': 200, 'svd__doc_topic_prior': 0.5, 'classifier__n_estimators': 300, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 3, 'classifier__max_depth': 15, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 55.36%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 30.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 32.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 59.44%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.05, 'svd__n_components': 40, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 400, 'classifier__min_samples_split': 4, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 50, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 61.01%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 33.2min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 35.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.77%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.05, 'svd__n_components': 20, 'svd__doc_topic_prior': 0.5, 'classifier__n_estimators': 400, 'classifier__min_samples_split': 15, 'classifier__min_samples_leaf': 5, 'classifier__max_depth': 70, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 61.29%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 30.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 31.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 55.42%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.1, 'svd__n_components': 30, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 1500, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 2, 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.1, 1: 0.9}, {0: 0.33, 1: 0.67}, {0: 0.1, 1: 0.9}, {0: 0.1, 1: 0.9}, {0: 0.1, 1: 0.9}, {0: 0.1, 1: 0.9}]}\n",
      "        Micro F1 (on outer loop): 60.37%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 22.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 24.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 55.92%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.1, 'svd__n_components': 35, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 300, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 3, 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 62.14%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 60.03% +/- 2.40\n",
      "        Micro Recall 69.79% +/- 4.29\n",
      "        Micro Precision 52.91% +/- 3.55\n",
      "        Hamming 12.60% +/- 1.13\n",
      "        Accuracy 56.25% +/- 3.12\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2, random=True, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific parameter grid\n",
    "n_estimators = [1500]\n",
    "max_depth = [20, 70] \n",
    "min_samples_split = [3, 15]\n",
    "min_samples_leaf = [2, 5]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "          [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}]]\n",
    "max_features = ['auto','log2']\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'classifier__max_features': max_features,\n",
    "        'svd__n_components':[30,40,200],\n",
    "        'svd__doc_topic_prior':[0.05],\n",
    "        'svd__topic_word_prior': [0.1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 22.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 53.56%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 20, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 1500, 'svd__doc_topic_prior': 0.05, 'svd__n_components': 40, 'svd__topic_word_prior': 0.1}\n",
      "        Micro F1 (on outer loop): 50.81%\n",
      "        Micro Recall (on outer loop): 69.97%\n",
      "        Micro Precision (on outer loop): 39.89%\n",
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 20.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 54.16%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 15, 'classifier__n_estimators': 1500, 'svd__doc_topic_prior': 0.05, 'svd__n_components': 40, 'svd__topic_word_prior': 0.1}\n",
      "        Micro F1 (on outer loop): 54.48%\n",
      "        Micro Recall (on outer loop): 75.72%\n",
      "        Micro Precision (on outer loop): 42.55%\n",
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 21.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 54.13%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 1500, 'svd__doc_topic_prior': 0.05, 'svd__n_components': 40, 'svd__topic_word_prior': 0.1}\n",
      "        Micro F1 (on outer loop): 54.61%\n",
      "        Micro Recall (on outer loop): 71.57%\n",
      "        Micro Precision (on outer loop): 44.15%\n",
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 21.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.19%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 20, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 15, 'classifier__n_estimators': 1500, 'svd__doc_topic_prior': 0.05, 'svd__n_components': 30, 'svd__topic_word_prior': 0.1}\n",
      "        Micro F1 (on outer loop): 54.33%\n",
      "        Micro Recall (on outer loop): 80.89%\n",
      "        Micro Precision (on outer loop): 40.90%\n",
      "Fitting 2 folds for each of 96 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 21.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 53.41%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 20, 'classifier__max_features': 'auto', 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 3, 'classifier__n_estimators': 1500, 'svd__doc_topic_prior': 0.05, 'svd__n_components': 40, 'svd__topic_word_prior': 0.1}\n",
      "        Micro F1 (on outer loop): 58.36%\n",
      "        Micro Recall (on outer loop): 73.65%\n",
      "        Micro Precision (on outer loop): 48.33%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 54.52% +/- 2.39\n",
      "        Micro Recall 74.36% +/- 3.80\n",
      "        Micro Precision 43.17% +/- 2.96\n",
      "        Hamming 16.86% +/- 1.59\n",
      "        Accuracy 45.69% +/- 5.18\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 XGBOOST with BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup \n",
    "lda = LatentDirichletAllocation(n_jobs=-1, random_state=0, max_iter = 100)\n",
    "clf = ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'aucpr', \n",
    "                                                        use_label_encoder=False, seed=0))\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                            ('classifier', clf)])\n",
    "XGB = Model_eval(dtm.bow, dtm.Y,\n",
    "                pipe,\n",
    "                'XGBOOST', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "space={ 'max_depth': hp.quniform(\"max_depth\", 2, 50, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'scale_pos_weight' : hp.uniform('scale_pos_weight', 0,5),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100,1000,50),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_components': hp.quniform('n_components', 10,500, 20),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [16:42<00:00, 33.41s/trial, best loss: -0.5749817117776153]\n",
      "Score on inner loop 0.5749817117776153 \n",
      " {'colsample_bytree': 0.8524563438340713, 'gamma': 4.229216728854999, 'learning_rate': 0.11569144902067507, 'max_depth': 30, 'min_child_weight': 8.0, 'n_estimators': 850, 'scale_pos_weight': 2.834374917301308, 'n_components': 140}\n",
      "\n",
      "100%|| 30/30 [33:35<00:00, 67.19s/trial, best loss: -0.5944170771756978]\n",
      "Score on inner loop 0.5944170771756978 \n",
      " {'colsample_bytree': 0.884761481334283, 'gamma': 4.3784786578727495, 'learning_rate': 0.12125679258741343, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 800, 'scale_pos_weight': 1.8973527277964992, 'n_components': 440}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.884761481334283, 'gamma': 4.3784786578727495, 'learning_rate': 0.12125679258741343, 'max_depth': 10, 'min_child_weight': 5.0, 'n_estimators': 800, 'scale_pos_weight': 1.8973527277964992, 'n_components': 440}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 62.00%\n",
      "        Micro Recall (on outer loop): 68.34%\n",
      "        Micro Precision (on outer loop): 56.73%\n",
      "\n",
      "100%|| 30/30 [39:10<00:00, 78.34s/trial, best loss: -0.5698729582577132]\n",
      "Score on inner loop 0.5698729582577132 \n",
      " {'colsample_bytree': 0.5475329584408251, 'gamma': 7.1507609857878425, 'learning_rate': 0.11845359579491789, 'max_depth': 15, 'min_child_weight': 1.0, 'n_estimators': 650, 'scale_pos_weight': 2.1571747101189818, 'n_components': 440}\n",
      "\n",
      "100%|| 30/30 [47:23<00:00, 94.78s/trial, best loss: -0.5257452574525746]\n",
      "Score on inner loop 0.5257452574525746 \n",
      " {'colsample_bytree': 0.9090419329355066, 'gamma': 1.1312885024248107, 'learning_rate': 0.14555691597062334, 'max_depth': 18, 'min_child_weight': 10.0, 'n_estimators': 150, 'scale_pos_weight': 3.0748547211961794, 'n_components': 340}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.5475329584408251, 'gamma': 7.1507609857878425, 'learning_rate': 0.11845359579491789, 'max_depth': 15, 'min_child_weight': 1.0, 'n_estimators': 650, 'scale_pos_weight': 2.1571747101189818, 'n_components': 440}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 61.78%\n",
      "        Micro Recall (on outer loop): 71.84%\n",
      "        Micro Precision (on outer loop): 54.19%\n",
      "\n",
      "100%|| 30/30 [33:29<00:00, 66.98s/trial, best loss: -0.5898305084745762]\n",
      "Score on inner loop 0.5898305084745762 \n",
      " {'colsample_bytree': 0.5675739202583223, 'gamma': 5.414822665189562, 'learning_rate': 0.09682904846861494, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 300, 'scale_pos_weight': 1.6269716572850634, 'n_components': 400}\n",
      "\n",
      "100%|| 30/30 [19:11<00:00, 38.40s/trial, best loss: -0.5569230769230769]\n",
      "Score on inner loop 0.5569230769230769 \n",
      " {'colsample_bytree': 0.6178232925682811, 'gamma': 7.719778526773265, 'learning_rate': 0.053751416812736506, 'max_depth': 5, 'min_child_weight': 7.0, 'n_estimators': 600, 'scale_pos_weight': 2.3892545177454267, 'n_components': 260}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.5675739202583223, 'gamma': 5.414822665189562, 'learning_rate': 0.09682904846861494, 'max_depth': 3, 'min_child_weight': 5.0, 'n_estimators': 300, 'scale_pos_weight': 1.6269716572850634, 'n_components': 400}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 53.23%\n",
      "        Micro Recall (on outer loop): 53.74%\n",
      "        Micro Precision (on outer loop): 52.73%\n",
      "\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 59.00% +/- 4.08\n",
      "        Micro Recall 64.64% +/- 7.84\n",
      "        Micro Precision 54.55% +/- 1.65\n",
      "        Hamming 12.07% +/- 0.62\n",
      "        Accuracy 61.94% +/- 0.60\n"
     ]
    }
   ],
   "source": [
    "XGB.perform_bayesian_opt_pre(space, max_evals=30, lda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.4 naive bayes with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lda = LatentDirichletAllocation(random_state=0, max_iter=100)\n",
    "clf =  ClassifierChain(GaussianNB(), order = 'random', random_state=0)\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                ('classifier', clf)])\n",
    "GNB = Model_eval(dtm.tfidf, dtm.Y, \n",
    "                 pipe,\n",
    "                 'Gaussian Naive Bayes',\n",
    "                 metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "grid = {'svd__n_components':[x for x in range(10,200,5)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Gaussian Naive Bayes\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  7.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.26%\n",
      "        Best parameters: {'svd__n_components': 150}\n",
      "        Micro F1 (on outer loop): 43.59%\n",
      "        Micro Recall (on outer loop): 66.77%\n",
      "        Micro Precision (on outer loop): 32.35%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 51.69%\n",
      "        Best parameters: {'svd__n_components': 170}\n",
      "        Micro F1 (on outer loop): 46.95%\n",
      "        Micro Recall (on outer loop): 71.25%\n",
      "        Micro Precision (on outer loop): 35.01%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  6.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.00%\n",
      "        Best parameters: {'svd__n_components': 160}\n",
      "        Micro F1 (on outer loop): 47.06%\n",
      "        Micro Recall (on outer loop): 74.51%\n",
      "        Micro Precision (on outer loop): 34.39%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  6.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 51.99%\n",
      "        Best parameters: {'svd__n_components': 165}\n",
      "        Micro F1 (on outer loop): 47.02%\n",
      "        Micro Recall (on outer loop): 70.38%\n",
      "        Micro Precision (on outer loop): 35.30%\n",
      "Fitting 2 folds for each of 38 candidates, totalling 76 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  76 out of  76 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 49.56%\n",
      "        Best parameters: {'svd__n_components': 175}\n",
      "        Micro F1 (on outer loop): 47.68%\n",
      "        Micro Recall (on outer loop): 71.75%\n",
      "        Micro Precision (on outer loop): 35.70%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 46.46% +/- 1.46\n",
      "        Micro Recall 70.93% +/- 2.50\n",
      "        Micro Precision 34.55% +/- 1.18\n",
      "        Hamming 22.15% +/- 0.71\n",
      "        Accuracy 38.54% +/- 2.46\n"
     ]
    }
   ],
   "source": [
    "GNB.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.5 Random Forest with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lda = LatentDirichletAllocation(random_state=0, max_iter = 100)\n",
    "clf = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                 ('classifier', clf)])\n",
    "RF = Model_eval(dtm.tfidf, dtm.Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_estimators = [800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "max_features = ['auto','sqrt','log2']\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__min_samples_leaf': min_samples_leaf,\n",
    "        'classifier__class_weight': weights,\n",
    "        'classifier__max_features': max_features,\n",
    "        'svd__n_components':[20,25,30,35,40,50,100,200,300, 400],\n",
    "        'svd__doc_topic_prior':[0.05,0.1,0.5,1],\n",
    "        'svd__topic_word_prior': [0.05,0.1,0.5,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 22.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 24.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 56.04%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.1, 'svd__n_components': 300, 'svd__doc_topic_prior': 0.5, 'classifier__n_estimators': 1500, 'classifier__min_samples_split': 10, 'classifier__min_samples_leaf': 3, 'classifier__max_features': 'auto', 'classifier__max_depth': 15, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 55.95%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 23.9min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 26.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 55.05%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.05, 'svd__n_components': 40, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 800, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'log2', 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 53.93%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 27.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 30.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 53.34%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.05, 'svd__n_components': 100, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 800, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 70, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 54.14%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 23.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 56.19%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.1, 'svd__n_components': 400, 'svd__doc_topic_prior': 1, 'classifier__n_estimators': 1500, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 20, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 57.58%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 18.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 52.55%\n",
      "        Best parameters: {'svd__topic_word_prior': 0.1, 'svd__n_components': 30, 'svd__doc_topic_prior': 0.5, 'classifier__n_estimators': 800, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 4, 'classifier__max_features': 'auto', 'classifier__max_depth': 100, 'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 57.91%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 55.90% +/- 1.67\n",
      "        Micro Recall 70.72% +/- 6.63\n",
      "        Micro Precision 46.53% +/- 2.03\n",
      "        Hamming 15.08% +/- 0.99\n",
      "        Accuracy 48.96% +/- 3.37\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2, random=True, iterations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more specific grid\n",
    "n_estimators = [1000]\n",
    "max_depth = [20,70] \n",
    "min_samples_split = [5,10]\n",
    "max_features = ['auto','sqrt']\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}]]\n",
    "grid = {'classifier__n_estimators': n_estimators,\n",
    "        'classifier__max_depth': max_depth,\n",
    "        'classifier__class_weight': weights,\n",
    "        'classifier__min_samples_split': min_samples_split,\n",
    "        'classifier__max_features':max_features,\n",
    "        'svd__n_components':[30,40,100,300],\n",
    "        'svd__doc_topic_prior':[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lda = LatentDirichletAllocation(n_jobs=-1, random_state=0, max_iter = 100, topic_word_prior=0.1)\n",
    "clf = RandomForestClassifier(random_state=0, min_samples_leaf = 4)\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                ('classifier', clf)])\n",
    "RF = Model_eval(dtm_tfidf, Y,\n",
    "                pipe,\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed: 15.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 59.29%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 20, 'classifier__max_features': 'auto', 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'svd__doc_topic_prior': 1, 'svd__n_components': 300}\n",
      "        Micro F1 (on outer loop): 57.84%\n",
      "        Micro Recall (on outer loop): 68.37%\n",
      "        Micro Precision (on outer loop): 50.12%\n",
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed: 15.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.65%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'svd__doc_topic_prior': 1, 'svd__n_components': 300}\n",
      "        Micro F1 (on outer loop): 62.55%\n",
      "        Micro Recall (on outer loop): 71.25%\n",
      "        Micro Precision (on outer loop): 55.75%\n",
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed: 15.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.09%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'svd__doc_topic_prior': 1, 'svd__n_components': 100}\n",
      "        Micro F1 (on outer loop): 57.92%\n",
      "        Micro Recall (on outer loop): 73.53%\n",
      "        Micro Precision (on outer loop): 47.77%\n",
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed: 15.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 56.79%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_split': 5, 'classifier__n_estimators': 1000, 'svd__doc_topic_prior': 1, 'svd__n_components': 300}\n",
      "        Micro F1 (on outer loop): 61.80%\n",
      "        Micro Recall (on outer loop): 70.06%\n",
      "        Micro Precision (on outer loop): 55.28%\n",
      "Fitting 2 folds for each of 64 candidates, totalling 128 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 128 out of 128 | elapsed: 15.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.57%\n",
      "        Best parameters: {'classifier__class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}], 'classifier__max_depth': 70, 'classifier__max_features': 'auto', 'classifier__min_samples_split': 10, 'classifier__n_estimators': 1000, 'svd__doc_topic_prior': 1, 'svd__n_components': 300}\n",
      "        Micro F1 (on outer loop): 60.42%\n",
      "        Micro Recall (on outer loop): 68.57%\n",
      "        Micro Precision (on outer loop): 54.00%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 60.10% +/- 1.94\n",
      "        Micro Recall 70.36% +/- 1.90\n",
      "        Micro Precision 52.58% +/- 3.12\n",
      "        Hamming 12.68% +/- 1.01\n",
      "        Accuracy 56.39% +/- 3.27\n"
     ]
    }
   ],
   "source": [
    "RF.perform_nested_CV(grid, inner_splits=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.6 XGBOOST with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "lda = LatentDirichletAllocation(n_jobs=-1, random_state=0, max_iter=100)\n",
    "clf = ClassifierChain(xgb.XGBClassifier(objective = \"binary:logistic\", eval_metric = 'aucpr', \n",
    "                                                        use_label_encoder=False, seed=0))\n",
    "pipe = Pipeline([('svd', lda),\n",
    "                            ('classifier', clf)])\n",
    "XGB = Model_eval(dtm.tfidf, dtm.Y,\n",
    "                pipe,\n",
    "                'xgboost', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter space\n",
    "space={ 'max_depth': hp.quniform(\"max_depth\", 2, 50, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'scale_pos_weight' : hp.uniform('scale_pos_weight', 0,5),\n",
    "        'n_estimators': hp.quniform('n_estimators', 100,1000,20),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.2),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_components': hp.quniform('n_components', 10,500, 20),\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                           | 0/30 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 50%|                       | 15/30 [08:22<10:21, 41.46s/trial, best loss: -0.5451612903225806]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [17:33<00:00, 35.10s/trial, best loss: -0.5493087557603686]\n",
      "Score on inner loop 0.5493087557603686 \n",
      " {'colsample_bytree': 0.8808647239660715, 'gamma': 2.5695069773598354, 'learning_rate': 0.09128362657592613, 'max_depth': 9, 'min_child_weight': 2.0, 'n_estimators': 260, 'scale_pos_weight': 4.695050421955056, 'n_components': 200}\n",
      "\n",
      "100%|| 30/30 [17:17<00:00, 34.59s/trial, best loss: -0.5711878685762425]\n",
      "Score on inner loop 0.5711878685762425 \n",
      " {'colsample_bytree': 0.7259177560821897, 'gamma': 7.4286979133304, 'learning_rate': 0.19990169572212912, 'max_depth': 32, 'min_child_weight': 1.0, 'n_estimators': 760, 'scale_pos_weight': 3.8251853087864736, 'n_components': 340}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.7259177560821897, 'gamma': 7.4286979133304, 'learning_rate': 0.19990169572212912, 'max_depth': 32, 'min_child_weight': 1.0, 'n_estimators': 760, 'scale_pos_weight': 3.8251853087864736, 'n_components': 340}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 55.39%\n",
      "        Micro Recall (on outer loop): 51.54%\n",
      "        Micro Precision (on outer loop): 59.87%\n",
      "\n",
      "  7%|                                            | 2/30 [00:20<04:18,  9.25s/trial, best loss: -0.4919454770755886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40%|                           | 12/30 [04:27<06:06, 20.35s/trial, best loss: -0.49844720496894407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|                          | 13/30 [05:02<07:00, 24.71s/trial, best loss: -0.49844720496894407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|                        | 14/30 [05:44<07:59, 29.97s/trial, best loss: -0.49844720496894407]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [16:46<00:00, 33.56s/trial, best loss: -0.5474576271186441]\n",
      "Score on inner loop 0.5474576271186441 \n",
      " {'colsample_bytree': 0.7361815854552042, 'gamma': 6.179232515312562, 'learning_rate': 0.09550622063938259, 'max_depth': 29, 'min_child_weight': 7.0, 'n_estimators': 320, 'scale_pos_weight': 4.0165605917825715, 'n_components': 300}\n",
      "\n",
      "100%|| 30/30 [36:01<00:00, 72.05s/trial, best loss: -0.5711711711711712]\n",
      "Score on inner loop 0.5711711711711712 \n",
      " {'colsample_bytree': 0.9077822815360623, 'gamma': 5.090204099300857, 'learning_rate': 0.19932543045540188, 'max_depth': 37, 'min_child_weight': 5.0, 'n_estimators': 620, 'scale_pos_weight': 3.504889891022607, 'n_components': 320}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.9077822815360623, 'gamma': 5.090204099300857, 'learning_rate': 0.19932543045540188, 'max_depth': 37, 'min_child_weight': 5.0, 'n_estimators': 620, 'scale_pos_weight': 3.504889891022607, 'n_components': 320}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 52.46%\n",
      "        Micro Recall (on outer loop): 59.20%\n",
      "        Micro Precision (on outer loop): 47.10%\n",
      "\n",
      " 53%|                      | 16/30 [13:28<15:27, 66.23s/trial, best loss: -0.5291005291005291]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [24:55<00:00, 49.87s/trial, best loss: -0.570999248685199]\n",
      "Score on inner loop 0.570999248685199 \n",
      " {'colsample_bytree': 0.7982291177279011, 'gamma': 6.993950815828568, 'learning_rate': 0.06307145786845687, 'max_depth': 5, 'min_child_weight': 9.0, 'n_estimators': 880, 'scale_pos_weight': 3.055582660408824, 'n_components': 220}\n",
      "\n",
      " 27%|                                   | 8/30 [09:32<30:15, 82.53s/trial, best loss: -0.4892881824464409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 33%|                               | 10/30 [12:25<28:11, 84.58s/trial, best loss: -0.4892881824464409]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_lda.py:806: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(-1.0 * perword_bound)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|| 30/30 [30:38<00:00, 61.27s/trial, best loss: -0.5910808767951626]\n",
      "Score on inner loop 0.5910808767951626 \n",
      " {'colsample_bytree': 0.5790142848118754, 'gamma': 8.015769540970314, 'learning_rate': 0.12545788148691056, 'max_depth': 14, 'min_child_weight': 0.0, 'n_estimators': 640, 'scale_pos_weight': 4.43282453610716, 'n_components': 180}\n",
      "\n",
      "Best hyperparameters found in inner loop\n",
      "{'colsample_bytree': 0.5790142848118754, 'gamma': 8.015769540970314, 'learning_rate': 0.12545788148691056, 'max_depth': 14, 'min_child_weight': 0.0, 'n_estimators': 640, 'scale_pos_weight': 4.43282453610716, 'n_components': 180}\n",
      "\n",
      "\n",
      "Performance on the outer test fold:\n",
      "        Micro F1 (on outer loop): 50.69%\n",
      "        Micro Recall (on outer loop): 56.24%\n",
      "        Micro Precision (on outer loop): 46.14%\n",
      "\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 52.85% +/- 1.94\n",
      "        Micro Recall 55.66% +/- 3.15\n",
      "        Micro Precision 51.04% +/- 6.26\n",
      "        Hamming 13.54% +/- 1.66\n",
      "        Accuracy 58.54% +/- 3.57\n"
     ]
    }
   ],
   "source": [
    "XGB.perform_bayesian_opt_pre(space,max_evals=30,lda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Interpretation of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize all models and every document-term matrix\n",
    "# bag of words document-term matrix\n",
    "cv = CountVectorizer()\n",
    "data_cv = cv.fit_transform(body.clean_text_lemma)\n",
    "dtm_CV = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "\n",
    "# tfidf document-term matrix\n",
    "tfidf = TfidfVectorizer()\n",
    "data_tfidf = tfidf.fit_transform(body.clean_text_lemma)\n",
    "dtm_tfidf = pd.DataFrame(data_tfidf.toarray(), columns=tfidf.get_feature_names())\n",
    "\n",
    "# lsa model\n",
    "lsa_obj = TruncatedSVD(n_components=30, \n",
    "                       n_iter=100, \n",
    "                       random_state=0)\n",
    "lsa_data = lsa_obj.fit_transform(dtm_tfidf)\n",
    "\n",
    "# lda model\n",
    "lda_obj = LatentDirichletAllocation(n_components=30,\n",
    "                                    doc_topic_prior = 0.1,\n",
    "                                    topic_word_prior = 1,\n",
    "                                    n_jobs=-1, random_state=0)\n",
    "lda_data = lda_obj.fit_transform(dtm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #5:\n",
      "locatie; prima; ontbijt; schoon; super; leuk; vriendelijk; personeel; kamer; top; ruim\n",
      "\n",
      "Topic #6:\n",
      "ligging; hotel; prima; heerlijk; schoon; perfect; centraal; mooi; centrum; leuk; sfeer\n",
      "\n",
      "Topic #7:\n",
      "ruim; schoon; bed; heerlijk; goed; zeer; mooi; kamer; fijn; prima; vriendelijk\n",
      "\n",
      "Topic #19:\n",
      "heerlijk; ruim; prijs; leuk; kwaliteit; sfeer; perfect; prima; zeer; verhouding; vriendelijkheid\n",
      "\n",
      "Topic #22:\n",
      "ok; leuk; parking; kamer; schoon; slecht; duur; sfeer; bed; proper; echt\n"
     ]
    }
   ],
   "source": [
    "# show terms per topic (LSA)\n",
    "words = cv.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lsa_obj.components_):\n",
    "    if topic_idx in [4,5,6,21,18]:\n",
    "        print(f\"\\nTopic #{topic_idx+1}:\")\n",
    "        print(\"; \".join([words[i]\n",
    "                         for i in topic.argsort()[:-10 - 2:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 best overall model: Random Forest (LSA & TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "      <th>topic_25</th>\n",
       "      <th>topic_26</th>\n",
       "      <th>topic_27</th>\n",
       "      <th>topic_28</th>\n",
       "      <th>topic_29</th>\n",
       "      <th>topic_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.220452</td>\n",
       "      <td>-0.008734</td>\n",
       "      <td>-0.103587</td>\n",
       "      <td>0.168713</td>\n",
       "      <td>-0.185408</td>\n",
       "      <td>-0.053710</td>\n",
       "      <td>0.159080</td>\n",
       "      <td>-0.026212</td>\n",
       "      <td>-0.059545</td>\n",
       "      <td>0.010566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.074412</td>\n",
       "      <td>0.027420</td>\n",
       "      <td>-0.024166</td>\n",
       "      <td>-0.032301</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>-0.036376</td>\n",
       "      <td>0.047393</td>\n",
       "      <td>-0.071422</td>\n",
       "      <td>0.058262</td>\n",
       "      <td>-0.074846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288873</td>\n",
       "      <td>0.362840</td>\n",
       "      <td>0.256717</td>\n",
       "      <td>-0.070316</td>\n",
       "      <td>-0.034638</td>\n",
       "      <td>-0.101037</td>\n",
       "      <td>0.064788</td>\n",
       "      <td>0.251172</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.028177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121869</td>\n",
       "      <td>-0.196991</td>\n",
       "      <td>-0.128109</td>\n",
       "      <td>0.183307</td>\n",
       "      <td>-0.086952</td>\n",
       "      <td>0.103356</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>-0.003148</td>\n",
       "      <td>0.062486</td>\n",
       "      <td>-0.123628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107330</td>\n",
       "      <td>-0.029813</td>\n",
       "      <td>-0.082443</td>\n",
       "      <td>-0.021691</td>\n",
       "      <td>-0.013626</td>\n",
       "      <td>-0.031462</td>\n",
       "      <td>-0.003643</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>0.034130</td>\n",
       "      <td>0.049533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075182</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>-0.057935</td>\n",
       "      <td>-0.032077</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.039275</td>\n",
       "      <td>-0.019420</td>\n",
       "      <td>0.046533</td>\n",
       "      <td>-0.050686</td>\n",
       "      <td>0.068111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.171783</td>\n",
       "      <td>-0.025601</td>\n",
       "      <td>-0.056247</td>\n",
       "      <td>0.184037</td>\n",
       "      <td>-0.171589</td>\n",
       "      <td>0.011134</td>\n",
       "      <td>0.125227</td>\n",
       "      <td>0.061108</td>\n",
       "      <td>-0.062927</td>\n",
       "      <td>-0.042401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011221</td>\n",
       "      <td>-0.069248</td>\n",
       "      <td>-0.014823</td>\n",
       "      <td>-0.072700</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>-0.006837</td>\n",
       "      <td>-0.042174</td>\n",
       "      <td>0.034377</td>\n",
       "      <td>-0.058677</td>\n",
       "      <td>-0.061328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162254</td>\n",
       "      <td>-0.009814</td>\n",
       "      <td>-0.073178</td>\n",
       "      <td>0.049973</td>\n",
       "      <td>-0.107763</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.091917</td>\n",
       "      <td>0.090793</td>\n",
       "      <td>-0.034750</td>\n",
       "      <td>0.033938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004619</td>\n",
       "      <td>0.038385</td>\n",
       "      <td>-0.018603</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>-0.016919</td>\n",
       "      <td>-0.012672</td>\n",
       "      <td>-0.038955</td>\n",
       "      <td>-0.037030</td>\n",
       "      <td>0.025487</td>\n",
       "      <td>0.169539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.144459</td>\n",
       "      <td>0.087097</td>\n",
       "      <td>-0.016517</td>\n",
       "      <td>-0.054912</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>0.029017</td>\n",
       "      <td>-0.049409</td>\n",
       "      <td>0.156483</td>\n",
       "      <td>-0.031348</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011802</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>-0.026340</td>\n",
       "      <td>0.046652</td>\n",
       "      <td>-0.093666</td>\n",
       "      <td>-0.011580</td>\n",
       "      <td>0.025816</td>\n",
       "      <td>-0.066553</td>\n",
       "      <td>0.089490</td>\n",
       "      <td>-0.020212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.174823</td>\n",
       "      <td>-0.070281</td>\n",
       "      <td>-0.089935</td>\n",
       "      <td>-0.035016</td>\n",
       "      <td>-0.053882</td>\n",
       "      <td>-0.041672</td>\n",
       "      <td>-0.012690</td>\n",
       "      <td>0.038849</td>\n",
       "      <td>-0.096499</td>\n",
       "      <td>-0.010124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054175</td>\n",
       "      <td>0.091357</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>-0.125202</td>\n",
       "      <td>-0.115444</td>\n",
       "      <td>-0.107565</td>\n",
       "      <td>-0.032380</td>\n",
       "      <td>-0.020275</td>\n",
       "      <td>-0.045148</td>\n",
       "      <td>-0.011398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.133588</td>\n",
       "      <td>-0.045624</td>\n",
       "      <td>-0.100263</td>\n",
       "      <td>-0.027744</td>\n",
       "      <td>-0.085157</td>\n",
       "      <td>-0.026445</td>\n",
       "      <td>-0.042928</td>\n",
       "      <td>0.042251</td>\n",
       "      <td>-0.040439</td>\n",
       "      <td>0.052429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024452</td>\n",
       "      <td>-0.020239</td>\n",
       "      <td>0.026310</td>\n",
       "      <td>0.078932</td>\n",
       "      <td>0.084116</td>\n",
       "      <td>0.016161</td>\n",
       "      <td>0.005659</td>\n",
       "      <td>0.052762</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.139142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.127711</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>-0.017367</td>\n",
       "      <td>-0.042730</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>-0.045208</td>\n",
       "      <td>-0.006475</td>\n",
       "      <td>-0.029624</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049468</td>\n",
       "      <td>0.078344</td>\n",
       "      <td>0.058965</td>\n",
       "      <td>0.017483</td>\n",
       "      <td>-0.039237</td>\n",
       "      <td>-0.056720</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.072665</td>\n",
       "      <td>-0.063735</td>\n",
       "      <td>-0.033220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.302285</td>\n",
       "      <td>-0.067585</td>\n",
       "      <td>-0.058016</td>\n",
       "      <td>0.122501</td>\n",
       "      <td>-0.208901</td>\n",
       "      <td>-0.129567</td>\n",
       "      <td>0.049305</td>\n",
       "      <td>0.040820</td>\n",
       "      <td>-0.178156</td>\n",
       "      <td>0.119758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062950</td>\n",
       "      <td>0.005665</td>\n",
       "      <td>0.053697</td>\n",
       "      <td>-0.008543</td>\n",
       "      <td>-0.025275</td>\n",
       "      <td>0.047222</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>-0.075012</td>\n",
       "      <td>-0.010746</td>\n",
       "      <td>0.221011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic_1   topic_2   topic_3   topic_4   topic_5   topic_6   topic_7  \\\n",
       "0     0.220452 -0.008734 -0.103587  0.168713 -0.185408 -0.053710  0.159080   \n",
       "1     0.288873  0.362840  0.256717 -0.070316 -0.034638 -0.101037  0.064788   \n",
       "2     0.107330 -0.029813 -0.082443 -0.021691 -0.013626 -0.031462 -0.003643   \n",
       "3     0.171783 -0.025601 -0.056247  0.184037 -0.171589  0.011134  0.125227   \n",
       "4     0.162254 -0.009814 -0.073178  0.049973 -0.107763  0.008977  0.091917   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1435  0.144459  0.087097 -0.016517 -0.054912  0.000945  0.029017 -0.049409   \n",
       "1436  0.174823 -0.070281 -0.089935 -0.035016 -0.053882 -0.041672 -0.012690   \n",
       "1437  0.133588 -0.045624 -0.100263 -0.027744 -0.085157 -0.026445 -0.042928   \n",
       "1438  0.127711  0.104919 -0.017367 -0.042730  0.021693 -0.045208 -0.006475   \n",
       "1439  0.302285 -0.067585 -0.058016  0.122501 -0.208901 -0.129567  0.049305   \n",
       "\n",
       "       topic_8   topic_9  topic_10  ...  topic_21  topic_22  topic_23  \\\n",
       "0    -0.026212 -0.059545  0.010566  ... -0.074412  0.027420 -0.024166   \n",
       "1     0.251172  0.174366  0.028177  ... -0.121869 -0.196991 -0.128109   \n",
       "2     0.010967  0.034130  0.049533  ...  0.075182  0.003402 -0.057935   \n",
       "3     0.061108 -0.062927 -0.042401  ...  0.011221 -0.069248 -0.014823   \n",
       "4     0.090793 -0.034750  0.033938  ... -0.004619  0.038385 -0.018603   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1435  0.156483 -0.031348  0.014174  ...  0.011802 -0.001884 -0.026340   \n",
       "1436  0.038849 -0.096499 -0.010124  ...  0.054175  0.091357  0.012763   \n",
       "1437  0.042251 -0.040439  0.052429  ...  0.024452 -0.020239  0.026310   \n",
       "1438 -0.029624  0.011327 -0.008080  ... -0.049468  0.078344  0.058965   \n",
       "1439  0.040820 -0.178156  0.119758  ...  0.062950  0.005665  0.053697   \n",
       "\n",
       "      topic_24  topic_25  topic_26  topic_27  topic_28  topic_29  topic_30  \n",
       "0    -0.032301  0.096700 -0.036376  0.047393 -0.071422  0.058262 -0.074846  \n",
       "1     0.183307 -0.086952  0.103356  0.035042 -0.003148  0.062486 -0.123628  \n",
       "2    -0.032077  0.033574  0.039275 -0.019420  0.046533 -0.050686  0.068111  \n",
       "3    -0.072700 -0.003408 -0.006837 -0.042174  0.034377 -0.058677 -0.061328  \n",
       "4     0.041900 -0.016919 -0.012672 -0.038955 -0.037030  0.025487  0.169539  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1435  0.046652 -0.093666 -0.011580  0.025816 -0.066553  0.089490 -0.020212  \n",
       "1436 -0.125202 -0.115444 -0.107565 -0.032380 -0.020275 -0.045148 -0.011398  \n",
       "1437  0.078932  0.084116  0.016161  0.005659  0.052762 -0.040533  0.139142  \n",
       "1438  0.017483 -0.039237 -0.056720  0.027041  0.072665 -0.063735 -0.033220  \n",
       "1439 -0.008543 -0.025275  0.047222  0.020157 -0.075012 -0.010746  0.221011  \n",
       "\n",
       "[1440 rows x 30 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make document-topic matrix\n",
    "doc_top_df = pd.DataFrame(lsa_data,\n",
    "                          columns = [f'topic_{r+1}' for r in range(30)])\n",
    "doc_top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to identify the most important topics per fold used for evaluation\n",
    "def important_predictors(classifier, dtm, Y, splits=5):\n",
    "    print(50 * '-', '\\n')\n",
    "    print('Algorithm:', 'random forest')\n",
    "    print('    Folds:')\n",
    "\n",
    "    # define the outer loop\n",
    "    cv = MultilabelStratifiedKFold(n_splits=splits, shuffle=True, random_state=0)\n",
    "\n",
    "    # loop over the different folds (using the index provided by the outer cv function)\n",
    "    fold = 1\n",
    "    for train_idx, valid_idx in list(cv.split(dtm, Y)):\n",
    "        # fit the model on the training fold \n",
    "        classifier.fit(dtm.iloc[train_idx,:], Y.iloc[train_idx,:]) \n",
    "        print()\n",
    "        print('     Fold:', fold)\n",
    "        print(pd.DataFrame(classifier.feature_importances_, \n",
    "                           index = dtm.columns, \n",
    "                           columns = ['importance']).sort_values('importance', ascending=False).iloc[:8,:])\n",
    "        fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: random forest\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "          importance\n",
      "topic_6     0.081826\n",
      "topic_7     0.049763\n",
      "topic_19    0.045684\n",
      "topic_27    0.036275\n",
      "topic_22    0.035410\n",
      "topic_10    0.035125\n",
      "topic_26    0.034618\n",
      "topic_15    0.033471\n",
      "\n",
      "     Fold: 2\n",
      "          importance\n",
      "topic_6     0.090355\n",
      "topic_7     0.047818\n",
      "topic_19    0.046439\n",
      "topic_5     0.039836\n",
      "topic_22    0.039017\n",
      "topic_9     0.035117\n",
      "topic_10    0.034225\n",
      "topic_16    0.033102\n",
      "\n",
      "     Fold: 3\n",
      "          importance\n",
      "topic_6     0.083717\n",
      "topic_19    0.049442\n",
      "topic_7     0.042395\n",
      "topic_22    0.041479\n",
      "topic_5     0.036586\n",
      "topic_10    0.034528\n",
      "topic_12    0.034433\n",
      "topic_14    0.033722\n",
      "\n",
      "     Fold: 4\n",
      "          importance\n",
      "topic_6     0.081583\n",
      "topic_7     0.050265\n",
      "topic_19    0.046059\n",
      "topic_22    0.039666\n",
      "topic_5     0.036825\n",
      "topic_12    0.036802\n",
      "topic_10    0.035601\n",
      "topic_9     0.035199\n",
      "\n",
      "     Fold: 5\n",
      "          importance\n",
      "topic_6     0.087813\n",
      "topic_19    0.046822\n",
      "topic_7     0.045198\n",
      "topic_12    0.037931\n",
      "topic_5     0.035972\n",
      "topic_22    0.035469\n",
      "topic_9     0.035295\n",
      "topic_26    0.033799\n"
     ]
    }
   ],
   "source": [
    "# most important topics\n",
    "rf = RandomForestClassifier(n_estimators = 800,\n",
    "                           max_depth = 50,\n",
    "                           min_samples_leaf = 4,\n",
    "                           min_samples_split = 3,\n",
    "                           max_features = 'log2',\n",
    "                           class_weight = [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}]) \n",
    "important_predictors(rf, doc_top_df, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Performance using 3 topics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only the important predictors to evaluate the models \n",
    "topics_small = doc_top_df.loc[:,['topic_6', 'topic_7','topic_19']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT PERFORMANCE\n",
    "RF = Model_eval(topics_small, Y, \n",
    "                RandomForestClassifier(random_state=0, n_estimators=800, n_jobs=-1),\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 43.33%\n",
      "        Micro Recall: 35.78%\n",
      "        Micro Precision: 54.90%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 51.25%\n",
      "        Micro Recall: 45.69%\n",
      "        Micro Precision: 58.37%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 52.34%\n",
      "        Micro Recall: 45.75%\n",
      "        Micro Precision: 61.14%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 48.26%\n",
      "        Micro Recall: 42.04%\n",
      "        Micro Precision: 56.65%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 44.49%\n",
      "        Micro Recall: 36.51%\n",
      "        Micro Precision: 56.93%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 47.93% +/- 3.57\n",
      "        Micro Recall 41.15% +/- 4.31\n",
      "        Micro Precision 57.60% +/- 2.08\n",
      "        Hamming 12.07% +/- 0.58\n",
      "        Accuracy 61.11% +/- 2.43\n",
      "        Macro F1 19.22% +/- 1.40\n"
     ]
    }
   ],
   "source": [
    "RF.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNED PERFORMANCE\n",
    "# initialize model \n",
    "RF_tuned = Model_eval(topics_small, Y, \n",
    "                RandomForestClassifier(random_state=0), \n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the parameter grid \n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "max_features = ['auto', 'log2']\n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'class_weight': weights}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 58.46%\n",
      "        Best parameters: {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'auto', 'max_depth': 100, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 54.86%\n",
      "        Micro Recall (on outer loop): 70.29%\n",
      "        Micro Precision (on outer loop): 44.99%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 59.35%\n",
      "        Best parameters: {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': 20, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 57.46%\n",
      "        Micro Recall (on outer loop): 67.09%\n",
      "        Micro Precision (on outer loop): 50.24%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.39%\n",
      "        Best parameters: {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 61.37%\n",
      "        Micro Recall (on outer loop): 71.90%\n",
      "        Micro Precision (on outer loop): 53.53%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   23.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.81%\n",
      "        Best parameters: {'n_estimators': 500, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 15, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.01, 1: 0.99}, {0: 0.33, 1: 0.67}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}]}\n",
      "        Micro F1 (on outer loop): 56.12%\n",
      "        Micro Recall (on outer loop): 64.97%\n",
      "        Micro Precision (on outer loop): 49.39%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 57.28%\n",
      "        Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 10, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.2, 1: 0.8}, {0: 0.33, 1: 0.67}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}, {0: 0.2, 1: 0.8}]}\n",
      "        Micro F1 (on outer loop): 58.01%\n",
      "        Micro Recall (on outer loop): 75.87%\n",
      "        Micro Precision (on outer loop): 46.95%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 57.56% +/- 2.19\n",
      "        Micro Recall 70.02% +/- 3.79\n",
      "        Micro Precision 49.02% +/- 2.91\n",
      "        Hamming 14.02% +/- 1.28\n",
      "        Accuracy 51.94% +/- 3.75\n",
      "        Macro F1 23.02% +/- 1.02\n"
     ]
    }
   ],
   "source": [
    "# perform random gridsearch\n",
    "RF_tuned.perform_nested_CV(grid, inner_splits=2, iterations = 100, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Performance using 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use only the important predictors to evaluate the models \n",
    "topics_small = doc_top_df.loc[:,['topic_6', 'topic_7','topic_19', 'topic_22', 'topic_5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model \n",
    "RF_tuned = Model_eval(topics_small, Y, \n",
    "                RandomForestClassifier(random_state=0), \n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the parameter grid \n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "max_features = ['auto', 'log2']\n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'class_weight': weights}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 60.64%\n",
      "        Best parameters: {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'auto', 'max_depth': 15, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 59.92%\n",
      "        Micro Recall (on outer loop): 70.93%\n",
      "        Micro Precision (on outer loop): 51.87%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 60.97%\n",
      "        Best parameters: {'n_estimators': 1000, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 70, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 57.91%\n",
      "        Micro Recall (on outer loop): 69.01%\n",
      "        Micro Precision (on outer loop): 49.88%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 59.65%\n",
      "        Best parameters: {'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 15, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 63.03%\n",
      "        Micro Recall (on outer loop): 73.53%\n",
      "        Micro Precision (on outer loop): 55.15%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 60.68%\n",
      "        Best parameters: {'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 50, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 60.18%\n",
      "        Micro Recall (on outer loop): 73.89%\n",
      "        Micro Precision (on outer loop): 50.77%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 59.74%\n",
      "        Best parameters: {'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': 10, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.01, 1: 0.99}, {0: 0.33, 1: 0.67}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}, {0: 0.01, 1: 0.99}]}\n",
      "        Micro F1 (on outer loop): 57.18%\n",
      "        Micro Recall (on outer loop): 80.32%\n",
      "        Micro Precision (on outer loop): 44.39%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 59.64% +/- 2.04\n",
      "        Micro Recall 73.53% +/- 3.83\n",
      "        Micro Precision 50.41% +/- 3.50\n",
      "        Hamming 13.55% +/- 1.63\n",
      "        Accuracy 53.12% +/- 5.35\n",
      "        Macro F1 23.43% +/- 0.85\n"
     ]
    }
   ],
   "source": [
    "# perform random gridsearch\n",
    "RF_tuned.perform_nested_CV(grid, inner_splits=2, iterations = 100, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Topics with best LDA model: Random Forest with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #1:\n",
      "nvt; ijsblokjes; gebrom; voorkant; bed; locatie; kamer; geur; hygine; ontbijt; ok\n",
      "\n",
      "Topic #2:\n",
      "sas; fantastisch; nvt; kamer; geur; hygine; ontbijt; ok; locatie; relaxen; niks\n",
      "\n",
      "Topic #3:\n",
      "uitklapbed; gehorigheid; hetgeen; loffiemachine; snachts; bieden; instructie; kind; type; papier; wifi\n",
      "\n",
      "Topic #4:\n",
      "kamer; ontbijt; goed; personeel; bed; locatie; hotel; vriendelijk; zeer; prima; heel\n",
      "\n",
      "Topic #5:\n",
      "salou; kos; lloret; bestemming; zelfde; feest; zoals; kwaliteit; bed; nvt; kamer\n",
      "\n",
      "Topic #6:\n",
      "kindvriendelijk; eu; kwalliteit; aanbeveel; hekemasl; hellemal; oneerlijk; tebinnen; kuisvrouw; oplader; slecht\n",
      "\n",
      "Topic #7:\n",
      "hygine; moelijk; tomtom; tekomen; self; dsn; pari; trap; moeite; waard; gifgro\n",
      "\n",
      "Topic #8:\n",
      "strijkplank; hardbed; gehorigheid; ontbyt; autos; hinder; ij; zakdoek; doos; lawaai; voet\n",
      "\n",
      "Topic #9:\n",
      "schreeuwen; show; dreigen; no; on; beginnen; klantvriendelijk; oplossing; zoeken; geven; gewoon\n",
      "\n",
      "Topic #10:\n",
      "vooraleer; duren; binnen; bedmaar; personeelvooral; receptionistewas; vuilzak; gedeeltelijk; nietkoelka; kondenconcierge; makenbij\n",
      "\n",
      "Topic #11:\n",
      "bizar; kwaliteitsverhouding; city; nisje; klets; borrelen; openhaard; lezen; prijs; bank; lobby\n",
      "\n",
      "Topic #12:\n",
      "et; schrijven; huis; kwart; luid; muziek; zev; tvkanal; technieker; eten; ni\n",
      "\n",
      "Topic #13:\n",
      "afvo; stinken; gozo; kamersnetheidvriendelijkheid; slaapgedeelte; afscheiden; inclusief; kaart; beperken; toilet; bar\n",
      "\n",
      "Topic #14:\n",
      "novotel; stijven; nietmeer; very; barman; nice; blijven; minder; ok; hotel; nvt\n",
      "\n",
      "Topic #15:\n",
      "tiptop; garanderen; accommondatie; totaalbedrag; blokkeren; mastercard; afhal; gelijk; mail; bedrag; boeking\n",
      "\n",
      "Topic #16:\n",
      "viesbloed; beddengoed; aankomst; geluids; oor; reziger; uitstekendv; isolatie; trein; temperatuur; lokatie\n",
      "\n",
      "Topic #17:\n",
      "perfekt; beteral; nadia; adequaat; handelen; klantvriendelijk; weinig; naam; klacht; zeer; ontbijt\n",
      "\n",
      "Topic #18:\n",
      "gastvriendelijkheid; nice; goed; nvt; kamer; geur; hygine; ontbijt; ok; locatie; relaxen\n",
      "\n",
      "Topic #19:\n",
      "ok; routebeschrijving; gedowngraded; cel; claustrofobisch; kamer; ligging; nvt; geur; hygine; ontbijt\n",
      "\n",
      "Topic #20:\n",
      "location; onbeveiligd; wifi; halte; watertaxi; direkt; waterbus; spido; grijpen; sfeergoededag; niksprijs\n",
      "\n",
      "Topic #21:\n",
      "relaxen; poets; verdiep; verdiepen; st; verschil; duidelijk; tussen; goed; ontbijt; kamer\n",
      "\n",
      "Topic #22:\n",
      "transport; starbuck; priveparking; luchthaven; lawaai; nvt; kamer; geur; hygine; ontbijt; ok\n",
      "\n",
      "Topic #23:\n",
      "milieuvriendelijkheid; uitmunten; ziekenhuis; verblijf; inmiddels; liggen; nvt; kamer; geur; hygine; ontbijt\n",
      "\n",
      "Topic #24:\n",
      "themas; benodigden; gedruppel; verschillend; luxe; leuk; flexibel; transparantie; afleven; raam; antwoorden\n",
      "\n",
      "Topic #25:\n",
      "defect; lift; dec; repareren; steil; week; trap; daardoor; redelijk; verdieping; lopen\n",
      "\n",
      "Topic #26:\n",
      "properheid; bereikbaarheid; toilet; locatie; ontbijt; nvt; kamer; geur; hygine; ok; relaxen\n",
      "\n",
      "Topic #27:\n",
      "menukaart; uitgebreid; mogen; nvt; kamer; geur; hygine; ontbijt; ok; locatie; relaxen\n",
      "\n",
      "Topic #28:\n",
      "balietoch; deskundig; ontbijtlocatie; allemaal; personeel; kamer; nvt; geur; hygine; ontbijt; ok\n",
      "\n",
      "Topic #29:\n",
      "verkeerd; overnachting; boeking; nvt; kamer; geur; hygine; ontbijt; ok; locatie; relaxen\n",
      "\n",
      "Topic #30:\n",
      "geur; slaapcomfor; luxe; ziekte; wijzigen; aangezien; beoordeling; boeking; slecht; kamer; nvt\n"
     ]
    }
   ],
   "source": [
    "# show terms per topic\n",
    "words = cv.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda_obj.components_):\n",
    "    print(f\"\\nTopic #{topic_idx+1}:\")\n",
    "    print(\"; \".join([words[i]\n",
    "                    for i in topic.argsort()[:-10 - 2:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "      <th>topic_5</th>\n",
       "      <th>topic_6</th>\n",
       "      <th>topic_7</th>\n",
       "      <th>topic_8</th>\n",
       "      <th>topic_9</th>\n",
       "      <th>topic_10</th>\n",
       "      <th>...</th>\n",
       "      <th>topic_21</th>\n",
       "      <th>topic_22</th>\n",
       "      <th>topic_23</th>\n",
       "      <th>topic_24</th>\n",
       "      <th>topic_25</th>\n",
       "      <th>topic_26</th>\n",
       "      <th>topic_27</th>\n",
       "      <th>topic_28</th>\n",
       "      <th>topic_29</th>\n",
       "      <th>topic_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.486550</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "      <td>0.017705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.413155</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "      <td>0.020236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.403247</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "      <td>0.020578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.523050</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "      <td>0.016447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.573819</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "      <td>0.014696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.538809</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "      <td>0.015903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.653450</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "      <td>0.011950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.572866</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "      <td>0.014729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.502238</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "      <td>0.017164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.695068</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.010515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic_1   topic_2   topic_3   topic_4   topic_5   topic_6   topic_7  \\\n",
       "0     0.017705  0.017705  0.017705  0.486550  0.017705  0.017705  0.017705   \n",
       "1     0.020236  0.020236  0.020236  0.413155  0.020236  0.020236  0.020236   \n",
       "2     0.020578  0.020578  0.020578  0.403247  0.020578  0.020578  0.020580   \n",
       "3     0.016447  0.016447  0.016447  0.523050  0.016447  0.016447  0.016447   \n",
       "4     0.014696  0.014696  0.014696  0.573819  0.014696  0.014696  0.014696   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1435  0.015903  0.015903  0.015903  0.538809  0.015903  0.015903  0.015903   \n",
       "1436  0.011950  0.011950  0.011950  0.653450  0.011950  0.011950  0.011950   \n",
       "1437  0.014729  0.014729  0.014729  0.572866  0.014729  0.014729  0.014729   \n",
       "1438  0.017164  0.017164  0.017164  0.502238  0.017164  0.017164  0.017164   \n",
       "1439  0.010515  0.010515  0.010515  0.695068  0.010515  0.010515  0.010515   \n",
       "\n",
       "       topic_8   topic_9  topic_10  ...  topic_21  topic_22  topic_23  \\\n",
       "0     0.017705  0.017705  0.017705  ...  0.017705  0.017705  0.017705   \n",
       "1     0.020236  0.020236  0.020236  ...  0.020236  0.020236  0.020236   \n",
       "2     0.020578  0.020578  0.020578  ...  0.020578  0.020578  0.020578   \n",
       "3     0.016447  0.016447  0.016447  ...  0.016447  0.016447  0.016447   \n",
       "4     0.014696  0.014696  0.014696  ...  0.014696  0.014696  0.014696   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1435  0.015903  0.015903  0.015903  ...  0.015903  0.015903  0.015903   \n",
       "1436  0.011950  0.011950  0.011950  ...  0.011950  0.011950  0.011950   \n",
       "1437  0.014729  0.014729  0.014729  ...  0.014729  0.014729  0.014729   \n",
       "1438  0.017164  0.017164  0.017164  ...  0.017164  0.017164  0.017164   \n",
       "1439  0.010515  0.010515  0.010515  ...  0.010515  0.010515  0.010515   \n",
       "\n",
       "      topic_24  topic_25  topic_26  topic_27  topic_28  topic_29  topic_30  \n",
       "0     0.017705  0.017705  0.017705  0.017705  0.017705  0.017705  0.017705  \n",
       "1     0.020236  0.020236  0.020236  0.020236  0.020236  0.020236  0.020236  \n",
       "2     0.020578  0.020578  0.020578  0.020578  0.020578  0.020578  0.020578  \n",
       "3     0.016447  0.016447  0.016447  0.016447  0.016447  0.016447  0.016447  \n",
       "4     0.014696  0.014696  0.014696  0.014696  0.014696  0.014696  0.014696  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1435  0.015903  0.015903  0.015903  0.015903  0.015903  0.015903  0.015903  \n",
       "1436  0.011950  0.011950  0.011950  0.011950  0.011950  0.011950  0.011950  \n",
       "1437  0.014729  0.014729  0.014729  0.014729  0.014729  0.014729  0.014729  \n",
       "1438  0.017164  0.017164  0.017164  0.017164  0.017164  0.017164  0.017164  \n",
       "1439  0.010515  0.010515  0.010515  0.010515  0.010515  0.010515  0.010515  \n",
       "\n",
       "[1440 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document-topic matrix\n",
    "doc_top_df = pd.DataFrame(lda_data,\n",
    "                          columns = [f'topic_{r+1}' for r in range(30)])\n",
    "doc_top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: random forest\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "          importance\n",
      "topic_4     0.061722\n",
      "topic_13    0.035024\n",
      "topic_16    0.034046\n",
      "topic_24    0.033699\n",
      "topic_15    0.033695\n",
      "topic_14    0.033547\n",
      "topic_19    0.033421\n",
      "topic_3     0.033286\n",
      "\n",
      "     Fold: 2\n",
      "          importance\n",
      "topic_4     0.062214\n",
      "topic_17    0.035986\n",
      "topic_12    0.034261\n",
      "topic_20    0.033733\n",
      "topic_23    0.033466\n",
      "topic_24    0.033226\n",
      "topic_1     0.033099\n",
      "topic_8     0.032965\n",
      "\n",
      "     Fold: 3\n",
      "          importance\n",
      "topic_4     0.063767\n",
      "topic_13    0.035150\n",
      "topic_20    0.034538\n",
      "topic_17    0.034389\n",
      "topic_12    0.034299\n",
      "topic_3     0.033862\n",
      "topic_5     0.033846\n",
      "topic_11    0.033498\n",
      "\n",
      "     Fold: 4\n",
      "          importance\n",
      "topic_4     0.068378\n",
      "topic_11    0.034200\n",
      "topic_19    0.033698\n",
      "topic_13    0.033550\n",
      "topic_30    0.033531\n",
      "topic_20    0.033290\n",
      "topic_17    0.033260\n",
      "topic_1     0.033010\n",
      "\n",
      "     Fold: 5\n",
      "          importance\n",
      "topic_4     0.065949\n",
      "topic_17    0.035219\n",
      "topic_14    0.034228\n",
      "topic_11    0.033289\n",
      "topic_22    0.033039\n",
      "topic_19    0.032944\n",
      "topic_23    0.032926\n",
      "topic_30    0.032733\n"
     ]
    }
   ],
   "source": [
    "# find important topics\n",
    "rf = RandomForestClassifier(n_estimators = 800,\n",
    "                           max_depth = 50,\n",
    "                           min_samples_leaf = 4,\n",
    "                           min_samples_split = 3,\n",
    "                           max_features = 'log2',\n",
    "                           class_weight = [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "                                           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}]) \n",
    "important_predictors(rf, doc_top_df, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# important topics identified\n",
    "topics_small = doc_top_df.loc[:,['topic_4','topic_13','topic_17']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT PERFORMANCE\n",
    "RF = Model_eval(topics_small, Y, \n",
    "                RandomForestClassifier(random_state=0, n_estimators=800, n_jobs=-1),\n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Folds:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     Fold: 1\n",
      "        Micro F1: 36.08%\n",
      "        Micro Recall: 32.91%\n",
      "        Micro Precision: 39.92%\n",
      "\n",
      "     Fold: 2\n",
      "        Micro F1: 40.57%\n",
      "        Micro Recall: 40.89%\n",
      "        Micro Precision: 40.25%\n",
      "\n",
      "     Fold: 3\n",
      "        Micro F1: 36.62%\n",
      "        Micro Recall: 38.24%\n",
      "        Micro Precision: 35.14%\n",
      "\n",
      "     Fold: 4\n",
      "        Micro F1: 34.20%\n",
      "        Micro Recall: 33.44%\n",
      "        Micro Precision: 35.00%\n",
      "\n",
      "     Fold: 5\n",
      "        Micro F1: 37.43%\n",
      "        Micro Recall: 39.68%\n",
      "        Micro Precision: 35.41%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 36.98% +/- 2.09\n",
      "        Micro Recall 37.03% +/- 3.27\n",
      "        Micro Precision 37.14% +/- 2.41\n",
      "        Hamming 17.07% +/- 0.87\n",
      "        Accuracy 50.76% +/- 1.66\n"
     ]
    }
   ],
   "source": [
    "RF.perform_CV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUNED PERFORMANCE\n",
    "# initialize model \n",
    "RF_tuned = Model_eval(topics_small, Y, \n",
    "                RandomForestClassifier(random_state=0), \n",
    "                'Random forest', \n",
    "               metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the parameter grid \n",
    "n_estimators = [100,200, 300, 400, 500, 800, 1000, 1500]\n",
    "max_depth = [2, 5, 10, 15, 20, 50, 70, 100] \n",
    "max_features = ['auto', 'log2']\n",
    "min_samples_split = [2, 3, 4, 5, 10, 15, 20]\n",
    "min_samples_leaf = [2, 3, 4 ,5, 10, 15, 20]\n",
    "weights = [[{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.3, 1:0.7}, {0:0.33, 1:0.67}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}, \n",
    "           {0:0.3, 1:0.7}, {0:0.3, 1:0.7}], \n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.4, 1:0.6}, {0:0.33, 1:0.67}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}, \n",
    "           {0:0.4, 1:0.6}, {0:0.4, 1:0.6}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.2, 1:0.8}, {0:0.33, 1:0.67}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}, \n",
    "           {0:0.2, 1:0.8}, {0:0.2, 1:0.8}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.1, 1:0.9}, {0:0.33, 1:0.67}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}, \n",
    "           {0:0.1, 1:0.9}, {0:0.1, 1:0.9}],\n",
    "           [{0:0.32, 1:0.68}, {0:0.34, 1:0.66}, \n",
    "           {0:0.01, 1:0.99}, {0:0.33, 1:0.67}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}, \n",
    "           {0:0.01, 1:0.99}, {0:0.01, 1:0.99}]]\n",
    "grid = {'n_estimators': n_estimators,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'class_weight': weights}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DB Accountancy\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------- \n",
      "\n",
      "Algorithm: Random forest\n",
      "    Inner loop:\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 51.38%\n",
      "        Best parameters: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 5, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 48.58%\n",
      "        Micro Recall (on outer loop): 81.79%\n",
      "        Micro Precision (on outer loop): 34.55%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 50.68%\n",
      "        Best parameters: {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 5, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 52.26%\n",
      "        Micro Recall (on outer loop): 81.15%\n",
      "        Micro Precision (on outer loop): 38.54%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 50.59%\n",
      "        Best parameters: {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 10, 'max_features': 'auto', 'max_depth': 5, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.4, 1: 0.6}, {0: 0.33, 1: 0.67}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}, {0: 0.4, 1: 0.6}]}\n",
      "        Micro F1 (on outer loop): 48.72%\n",
      "        Micro Recall (on outer loop): 83.99%\n",
      "        Micro Precision (on outer loop): 34.31%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 50.02%\n",
      "        Best parameters: {'n_estimators': 200, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 5, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 50.09%\n",
      "        Micro Recall (on outer loop): 86.62%\n",
      "        Micro Precision (on outer loop): 35.23%\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Best Micro F1 score (inner test folds): 49.95%\n",
      "        Best parameters: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 5, 'class_weight': [{0: 0.32, 1: 0.68}, {0: 0.34, 1: 0.66}, {0: 0.3, 1: 0.7}, {0: 0.33, 1: 0.67}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}, {0: 0.3, 1: 0.7}]}\n",
      "        Micro F1 (on outer loop): 49.95%\n",
      "        Micro Recall (on outer loop): 85.08%\n",
      "        Micro Precision (on outer loop): 35.36%\n",
      "\n",
      "    Average over all folds:\n",
      "        Micro F1 49.92% +/- 1.32\n",
      "        Micro Recall 83.73% +/- 2.03\n",
      "        Micro Precision 35.60% +/- 1.52\n",
      "        Hamming 22.80% +/- 1.33\n",
      "        Accuracy 29.79% +/- 4.34\n"
     ]
    }
   ],
   "source": [
    "# perform random gridsearch\n",
    "RF_tuned.perform_nested_CV(grid, inner_splits=2, iterations = 100, random=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much lower performance than with the LSA topic model. Could be expected since the tuned number of topics needed to obtain a good performance was much higher in the LDA model than the LSA model. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Geen",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
